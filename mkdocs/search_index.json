{
    "docs": [
        {
            "location": "/", 
            "text": "Polgraw all-sky search for almost monochromatic gravitational wave signals.\n\n\nPipeline flowchart\n\n\n\n\n\n\n\n\n\n\nTopics\n\n\n\n\nInput data generation\n \n\n\nF-statistic CW search for candidate signals\n\n\nCoincidences among candidate signals\n\n\nPipeline script\n\n\nDocuments and publications\n\n\n\n\nContributors\n\n\nIn alphabetic order:\n\n\n\n\nMicha\u0142 Bejger\n\n\nJan Bolek\n\n\nPawe\u0142 Cieciel\u0105g\n\n\nOrest Dorosh\n\n\nAleksander Garus\n\n\nAndrzej Kr\u00f3lak\n\n\nMaciej Pi\u0119tka\n\n\nGevorg Poghosyan\n\n\nMagdalena Sieniawska \n\n\nRafa\u0142 Skrzypiec", 
            "title": "Home"
        }, 
        {
            "location": "/#polgraw-all-sky-search-for-almost-monochromatic-gravitational-wave-signals", 
            "text": "", 
            "title": "Polgraw all-sky search for almost monochromatic gravitational wave signals."
        }, 
        {
            "location": "/#pipeline-flowchart", 
            "text": "", 
            "title": "Pipeline flowchart"
        }, 
        {
            "location": "/#topics", 
            "text": "Input data generation    F-statistic CW search for candidate signals  Coincidences among candidate signals  Pipeline script  Documents and publications", 
            "title": "Topics"
        }, 
        {
            "location": "/#contributors", 
            "text": "In alphabetic order:   Micha\u0142 Bejger  Jan Bolek  Pawe\u0142 Cieciel\u0105g  Orest Dorosh  Aleksander Garus  Andrzej Kr\u00f3lak  Maciej Pi\u0119tka  Gevorg Poghosyan  Magdalena Sieniawska   Rafa\u0142 Skrzypiec", 
            "title": "Contributors"
        }, 
        {
            "location": "/input_data/", 
            "text": "Input data generation\n\n\nextract_band\n\n\nThis program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").\n\n\nPrerequisites\n\n\nC compiller. Uses standard C libraries, \nlibm\n. Links to the PSS library (created by Pia Astone).\n\n\nHow to run it?\n\n\n extract_band \n input_file\n\n\n\n\nwhere \ninput_file\n is an ASCII file contaning the following rows:  \n\n\n\n\nMaximal number of SFT\n\n\nThe name of the output file\n\n\nThe list of SFT files\n\n\nThe frequency band in Hz\n\n\nThe width of frequency band in Hz\n\n\n\n\nfor example: \n\n\n100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1\n\n\n\n\nOutput\n\n\nExample output: \n\n\n% Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT\n% 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20\n% FFT number in the file; Beginning mjd days; Gps s; Gps ns;\n% 100 55099.5879745370 937922816 0\n 4.59662571e+02  2.27630825e+01\n-3.50387007e+02 -2.20005558e+02\n 3.57587904e+02  1.01217077e+02\n 1.74400486e+02  2.62086552e+02\n 2.21804800e+02 -5.20278366e+02\n-3.87826732e+02 -1.55758978e+02\n\n\n\n\ngen2day\n description\n\n\n...", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#input-data-generation", 
            "text": "", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#extract_band", 
            "text": "This program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").", 
            "title": "extract_band"
        }, 
        {
            "location": "/input_data/#prerequisites", 
            "text": "C compiller. Uses standard C libraries,  libm . Links to the PSS library (created by Pia Astone).", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/input_data/#how-to-run-it", 
            "text": "extract_band   input_file  where  input_file  is an ASCII file contaning the following rows:     Maximal number of SFT  The name of the output file  The list of SFT files  The frequency band in Hz  The width of frequency band in Hz   for example:   100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1", 
            "title": "How to run it?"
        }, 
        {
            "location": "/input_data/#output", 
            "text": "Example output:   % Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT\n% 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20\n% FFT number in the file; Beginning mjd days; Gps s; Gps ns;\n% 100 55099.5879745370 937922816 0\n 4.59662571e+02  2.27630825e+01\n-3.50387007e+02 -2.20005558e+02\n 3.57587904e+02  1.01217077e+02\n 1.74400486e+02  2.62086552e+02\n 2.21804800e+02 -5.20278366e+02\n-3.87826732e+02 -1.55758978e+02", 
            "title": "Output"
        }, 
        {
            "location": "/input_data/#gen2day-description", 
            "text": "...", 
            "title": "gen2day description"
        }, 
        {
            "location": "/search_for_candidates/", 
            "text": "F-statistic candidate signal search\n\n\nProduction serial code for a network of detectors is available at \nhere\n. \nOpenMP\n version is at \nthis location\n. To get the whole pipeline, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n. \n\n\nAlgorithm flowchart\n\n\n\n\n\n\n1. Prerequisites\n\n\nThe code is written in standard \nC\n. \nGNU Scientific Library (GSL)\n and the \nFFTW library\n (version 3.0 or later) are needed to run the code. \nGNU struct dirent\n objects are used to read the directories. \n\n\nOptionally, \nSLEEF\n or \nYEPPP!\n, libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in \nsrc/lib\n. The choice which of these libraries to use has to be made at compilation time by modifying the \nMakefile\n. \n\n\n2. Compilation. Example for serial CPU code\n\n\nRun  \nmake gwsearch-cpu\n or \nmake\n in \nsearch/network/src-cpu\n (default \nC\n version not-optimized with \nopenMP\n; for the \nopenMP\n version see the \nsearch/network/src-openmp\n directory). Resulting  binary is called \ngwsearch-cpu\n. Modify the \nMakefile\n to fit your system. By default the \nYEPPP!\n library is selected. \n\n\n3. How to run the program?\n\n\nMinimal call to \ngwsearch-cpu\n is as follows (code compiled with the \nGNUSINCOS\n option): \n\n\n./gwsearch-cpu -d data_dir -o output_dir -i frame -b band\n\n\n\n\nwhere\n\n\n\n\ndata_dir\n is the base directory of input data files,\n\n\noutput_dir\nis a directory to write the output,\n\n\nframe\n is the number of time frame to be analyzed,\n\n\nband\n is the number of the frequency band (see the \ndata structure\n description for details). \n\n\n\n\n\n\n3.1. Full list of switches\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-d, -data\n\n\nData directory (default is \n.\n)\n\n\n\n\n\n\n-o, -output\n\n\nOutput directory (default is \n./candidates\n)\n\n\n\n\n\n\n-i, -ident\n\n\nFrame number\n\n\n\n\n\n\n-b, -band\n\n\nBand number\n\n\n\n\n\n\n-l, -label\n\n\nCustom label for the input and output files\n\n\n\n\n\n\n-r, -range\n\n\nUse file with grid range or pulsar position\n\n\n\n\n\n\n-g, -getrange\n\n\nWrite grid ranges \n save fft wisdom \n exit (ignore -r)\n\n\n\n\n\n\n-c, -cwd\n\n\nChange to directory \ndir\n\n\n\n\n\n\n-t, -threshold\n\n\nThreshold for the F-statistic (default is \n20\n)\n\n\n\n\n\n\n-h, -hemisphere\n\n\nHemisphere (default is 0 - does both)\n\n\n\n\n\n\n-p, -fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-s, -dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-u, -usedet\n\n\nUse only detectors from string (default is \nuse all available\n)\n\n\n\n\n\n\n-x, -addsig\n\n\nAdd signal with parameters from \nfile\n\n\n\n\n\n\n-n, -narrowdown\n\n\nNarrow-down the frequency band (range \n[0, 0.5] +- around center\n)\n\n\n\n\n\n\n\n\nAlso: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--whitenoise\n\n\nWhite Gaussian noise assumed\n\n\n\n\n\n\n--nospindown\n\n\nSpindowns neglected\n\n\n\n\n\n\n--nocheckpoint\n\n\nState file will not be created (no checkpointing)\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\n3.2. Network of detectors\n\n\nFor the examplary input data time streams \nxdatc_001_0101.bin\n provided in \ntest-data-network.tar.gz\n, the call is as follows:\n\n\nLD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu -data ./test-data-network -ident 001 -band 0101 -usedet H1V1\n\n\n\n\nwhere the \nLD_LIBRARY_PATH\n points to the location of the \nYEPPP!\n library. \n\n\nThe program will proceed assuming that the data directory \n./test-data-network/001\n for the time frame \n001\n contain subdirectories for the network of detectors (here \nH1\n and \nV1\n) with input time series \nxdatc_001_0101.bin\n and the ephemerids files \nDetSSB.bin\n in each subdirectory. The grid of parameters files is expected to be in \n./test-data-network/001/grid.bin\n. Switch \n-usedet H1\n (\n-usedet V1\n) select the appropriate data and performs single detector search. \n\n\n\n\n3.3. Network of detectors in spotlight search (depreciated)\n\n\nFor the \nH1L1\n network of detectors, using the \ntest-data-network-injection.tar.gz\n to search towards a pre-defined direction (spotlight search) in one 2-day segment:\n\n\nLD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./search -data ./test-data-network-injection -ident 205 -band 000 -spotlight ./test-data-network-injection/205/spot_J0322+0441.dat -fpo 1391.3 -label J0322+0441 -dt 2  \n\n\n\n\nThe injection corresponds to a pulsar J0322+0441. Note the differences with respect to the minimal call: \n\n\n\n\ninstead of calculating the band frequency \nfpo\n from \nband\n, we provide it directly with the \n-fpo\n switch (\n-band 000\n is invoked for legacy), \n\n\nthe input data is denoted with the pulsar label, hence the \n-label\n switch, \n\n\nthe sampling time \ndt\n is now set to \n2 s\n,\n\n\n-spotlight\n switch points to the location of the spotlight file which contains the list of sky positions, and corresponding number and values of spindowns, in the following format: \n\\begin{equation} \nh\\, N_{sky}\\, m_1\\, n_1\\, N^s_{1}\\, s_{1}\\, \\dots\\, s_{N^s_1}\\, \nm_2\\, n_2\\, N^s_{2}\\, s_1\\, \\dots\\, s_{N^s_2}\\, \\dots,\n\n\\end{equation} \nwhere \n$h$\n is the hemisphere number (1 or 2), \n$N_{sky}$\n is the total number of sky positions in a given spotlight search, \n$m_i$\n and \n$n_i$\n are the sky positions in linear (grid) coordinates, \n$N^s_{i}$\n is the number of spindowns, and \n$s_{i}\\,\\dots\\, s_{N^s_i}$\n and the spindowns (in linear coordinates), corresponding to the \n$i-$\nth sky position.    \n\n\n\n\nResults are as follows: \n\n\n\n\n3.4. One-detector version\n\n\nIn the case of \none-detector\n version, test data is in \ntest-data.tar.gz\n. The directory \n001\n contains directly the \nDetSSB.bin\n, \ngrid.bin\n and \nxdatc_001_101.bin\n files. \n\n\n4. Data structure\n\n\n \nWe describe the structure using the VSR1 data as an example. \nTime of the first sample in MJD (Modified Julian Date) is 54239.00 \n(corresponding to 2007/05/18, UTC 12:00). \n\n\nIn this run the data was divided into 68 time frames, each of them 2 \nsideral  days  long, rounded to half second (172328 seconds each). \nSince we use the sampling time of \n0.5s\n, total number of data points \nin each time frame is \nN=344656\n. \n\n\nFrames are labelled with three-digit consecutive number, \nfrom \n001\n to \n068\n. Frame label is the name of a subfolder, containing \nall narrowband sequences corresponding to that frame, e.g., \n./042\n.\n\n\nBeginning MJD of each time frame is saved in the \nnnn/starting_date\n \nfile:\n\n\n   % cat 042/starting_date\n   54320.7760185185\n\n\n\n\nReference band frequency \nfpo\n is defined for each band as \n\n$$ \nfpo = 100 + (1 - 2^{-5})\\cdot bbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]},\n$$\n\nwhere \nbbb\n is the band number, and \ndt\n is the data sampling time (\n0.5 s\n for VSR1 data). \n\nVSR1\n database contains 929 narrow (1 Hz, \n$B=1/(2dt)$\n) bands, covering the range \n100 - 1000 Hz. Neighboring bands overlap by 0.03125 Hz. \n\n\n\n\n4.1 O1 change of sampling \ndt\n (bandwidth \nB\n) and data length\n\n\nFor the \nO1\n data, the bandwidth was chosen to be \n0.25 Hz\n (\ndt\n was chosen to be equal \n2 s\n). Consequently, the reference band frequency \nfpo\n is defined as \n\n$$\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \n$$\n\n\nO1\n data thus contains \n${\\simeq} 2000$\n narrow \n0.25 Hz\n bands in the frequency range \n10-500 Hz\n. Because of the sampling time change, the total number of data points in the 2 sideral day long segment is \nN=86164\n. For lower frequencies 6 day length segments are used. They contain \nN=258492\n double-precision numbers. \n\n\n5. Input data files\n\n\nA single run requires 2 data files for each detector \nDD\n, stored in \ndata_dir/nnn/DD\n \nsubdirectory, where \nDD\n is \nH1\n (Hanford), \nL1\n (Livingston), or \nV1\n (Virgo Cascina):\n\n\n\n\n\n\nxdat_nnn_bbb.bin\n - time-domain narrow-band data sequence, sampled\n     at  half second. \nnnn\n is the number of time frame, \nbbb\n is the\n     number of frequency band,\n\n\n\n\n\n\nDetSSB.bin\n  -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in\n     Cartesian coordinates, sampled at half second (3dim array of size \nN\n). \n     Last two records\n     of  this file  are the angle \nphir\n, determining the  position of\n     Earth in  its diurnal motion, and the obliquity of  the ecliptic\n     \nepsm\n, both calculated for the first sample of the data,\n\n\n\n\n\n\nas we as the sky positions-frequency-spindown grid file in linear coordinates \n(common for all the detectors), stored in \ndata_dir/nnn\n: \n\n\n\n\ngrid.bin\n - generator matrix of an optimal grid of templates. \n\n\n\n\n6. Output files\n\n\nBinary output  files,   containing  trigger  events   above  an  arbitrary\nthreshold, are written to  the output_dir directory.  There are two output\nfiles for every input data sequence: \ntriggers_nnn_bbb_1.bin\n and\n\ntriggers_nnn_bbb_2.bin\n,  where  \n1\n  and  \n2\n correspond to  northern  and\nsouthern  ecliptic  hemisphere. Every trigger (candidate) event  occupies \n40\n\nconsecutive bytes (5 double numbers), with the following meaning:\n\n\n\n\n\n\n\n\nRecord no.\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\nfrequency [radians, between 0 and \n$\\pi$\n] above \nfpo\n\n\n\n\n\n\n2\n\n\nspindown [Hz s\n-1\n]\n\n\n\n\n\n\n3\n\n\ndeclination [radians]\n\n\n\n\n\n\n4\n\n\nright ascension [radians]\n\n\n\n\n\n\n5\n\n\nsignal to noise ratio\n\n\n\n\n\n\n\n\n7. Auxiliary files\n\n\nThere is a couple of auxiliary files created by the \nsearch\n \nin the working directory:\n\n\n\n\n\n\nwisdom-hostname.dat\n - \"wisdom\" file created by the \nFFTW\n. The \nhostname\n \nvariable is determined by a call to \ngethostname()\n, \n\n\n\n\n\n\nstate_nnn_bbb.dat\n - checkpoint file.  The  search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.\n\n\n\n\n\n\n8. Versions\n\n\nPolgraw-allsky code comes also as an\n\nMPI\n,\n\nnetwork of detectors spotlight\nsearch\n and a\n\nGPU\n version.", 
            "title": "Search for candidate signals"
        }, 
        {
            "location": "/search_for_candidates/#f-statistic-candidate-signal-search", 
            "text": "Production serial code for a network of detectors is available at  here .  OpenMP  version is at  this location . To get the whole pipeline, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "F-statistic candidate signal search"
        }, 
        {
            "location": "/search_for_candidates/#algorithm-flowchart", 
            "text": "", 
            "title": "Algorithm flowchart"
        }, 
        {
            "location": "/search_for_candidates/#1-prerequisites", 
            "text": "The code is written in standard  C .  GNU Scientific Library (GSL)  and the  FFTW library  (version 3.0 or later) are needed to run the code.  GNU struct dirent  objects are used to read the directories.   Optionally,  SLEEF  or  YEPPP! , libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in  src/lib . The choice which of these libraries to use has to be made at compilation time by modifying the  Makefile .", 
            "title": "1. Prerequisites"
        }, 
        {
            "location": "/search_for_candidates/#2-compilation-example-for-serial-cpu-code", 
            "text": "Run   make gwsearch-cpu  or  make  in  search/network/src-cpu  (default  C  version not-optimized with  openMP ; for the  openMP  version see the  search/network/src-openmp  directory). Resulting  binary is called  gwsearch-cpu . Modify the  Makefile  to fit your system. By default the  YEPPP!  library is selected.", 
            "title": "2. Compilation. Example for serial CPU code"
        }, 
        {
            "location": "/search_for_candidates/#3-how-to-run-the-program", 
            "text": "Minimal call to  gwsearch-cpu  is as follows (code compiled with the  GNUSINCOS  option):   ./gwsearch-cpu -d data_dir -o output_dir -i frame -b band  where   data_dir  is the base directory of input data files,  output_dir is a directory to write the output,  frame  is the number of time frame to be analyzed,  band  is the number of the frequency band (see the  data structure  description for details).", 
            "title": "3. How to run the program?"
        }, 
        {
            "location": "/search_for_candidates/#31-full-list-of-switches", 
            "text": "Switch  Description      -d, -data  Data directory (default is  . )    -o, -output  Output directory (default is  ./candidates )    -i, -ident  Frame number    -b, -band  Band number    -l, -label  Custom label for the input and output files    -r, -range  Use file with grid range or pulsar position    -g, -getrange  Write grid ranges   save fft wisdom   exit (ignore -r)    -c, -cwd  Change to directory  dir    -t, -threshold  Threshold for the F-statistic (default is  20 )    -h, -hemisphere  Hemisphere (default is 0 - does both)    -p, -fpo  Reference band frequency  fpo  value    -s, -dt  Data sampling time dt (default value:  0.5 )    -u, -usedet  Use only detectors from string (default is  use all available )    -x, -addsig  Add signal with parameters from  file    -n, -narrowdown  Narrow-down the frequency band (range  [0, 0.5] +- around center )     Also:            --whitenoise  White Gaussian noise assumed    --nospindown  Spindowns neglected    --nocheckpoint  State file will not be created (no checkpointing)    --help  This help", 
            "title": "3.1. Full list of switches"
        }, 
        {
            "location": "/search_for_candidates/#32-network-of-detectors", 
            "text": "For the examplary input data time streams  xdatc_001_0101.bin  provided in  test-data-network.tar.gz , the call is as follows:  LD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu -data ./test-data-network -ident 001 -band 0101 -usedet H1V1  where the  LD_LIBRARY_PATH  points to the location of the  YEPPP!  library.   The program will proceed assuming that the data directory  ./test-data-network/001  for the time frame  001  contain subdirectories for the network of detectors (here  H1  and  V1 ) with input time series  xdatc_001_0101.bin  and the ephemerids files  DetSSB.bin  in each subdirectory. The grid of parameters files is expected to be in  ./test-data-network/001/grid.bin . Switch  -usedet H1  ( -usedet V1 ) select the appropriate data and performs single detector search.", 
            "title": "3.2. Network of detectors"
        }, 
        {
            "location": "/search_for_candidates/#33-network-of-detectors-in-spotlight-search-depreciated", 
            "text": "For the  H1L1  network of detectors, using the  test-data-network-injection.tar.gz  to search towards a pre-defined direction (spotlight search) in one 2-day segment:  LD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./search -data ./test-data-network-injection -ident 205 -band 000 -spotlight ./test-data-network-injection/205/spot_J0322+0441.dat -fpo 1391.3 -label J0322+0441 -dt 2    The injection corresponds to a pulsar J0322+0441. Note the differences with respect to the minimal call:    instead of calculating the band frequency  fpo  from  band , we provide it directly with the  -fpo  switch ( -band 000  is invoked for legacy),   the input data is denoted with the pulsar label, hence the  -label  switch,   the sampling time  dt  is now set to  2 s ,  -spotlight  switch points to the location of the spotlight file which contains the list of sky positions, and corresponding number and values of spindowns, in the following format: \n\\begin{equation} \nh\\, N_{sky}\\, m_1\\, n_1\\, N^s_{1}\\, s_{1}\\, \\dots\\, s_{N^s_1}\\, \nm_2\\, n_2\\, N^s_{2}\\, s_1\\, \\dots\\, s_{N^s_2}\\, \\dots, \n\\end{equation} \nwhere  $h$  is the hemisphere number (1 or 2),  $N_{sky}$  is the total number of sky positions in a given spotlight search,  $m_i$  and  $n_i$  are the sky positions in linear (grid) coordinates,  $N^s_{i}$  is the number of spindowns, and  $s_{i}\\,\\dots\\, s_{N^s_i}$  and the spindowns (in linear coordinates), corresponding to the  $i-$ th sky position.       Results are as follows:", 
            "title": "3.3. Network of detectors in spotlight search (depreciated)"
        }, 
        {
            "location": "/search_for_candidates/#34-one-detector-version", 
            "text": "In the case of  one-detector  version, test data is in  test-data.tar.gz . The directory  001  contains directly the  DetSSB.bin ,  grid.bin  and  xdatc_001_101.bin  files.", 
            "title": "3.4. One-detector version"
        }, 
        {
            "location": "/search_for_candidates/#4-data-structure", 
            "text": "We describe the structure using the VSR1 data as an example. \nTime of the first sample in MJD (Modified Julian Date) is 54239.00 \n(corresponding to 2007/05/18, UTC 12:00).   In this run the data was divided into 68 time frames, each of them 2 \nsideral  days  long, rounded to half second (172328 seconds each). \nSince we use the sampling time of  0.5s , total number of data points \nin each time frame is  N=344656 .   Frames are labelled with three-digit consecutive number, \nfrom  001  to  068 . Frame label is the name of a subfolder, containing \nall narrowband sequences corresponding to that frame, e.g.,  ./042 .  Beginning MJD of each time frame is saved in the  nnn/starting_date  \nfile:     % cat 042/starting_date\n   54320.7760185185  Reference band frequency  fpo  is defined for each band as  $$ \nfpo = 100 + (1 - 2^{-5})\\cdot bbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]},\n$$ \nwhere  bbb  is the band number, and  dt  is the data sampling time ( 0.5 s  for VSR1 data).  VSR1  database contains 929 narrow (1 Hz,  $B=1/(2dt)$ ) bands, covering the range \n100 - 1000 Hz. Neighboring bands overlap by 0.03125 Hz.", 
            "title": "4. Data structure"
        }, 
        {
            "location": "/search_for_candidates/#41-o1-change-of-sampling-dt-bandwidth-b-and-data-length", 
            "text": "For the  O1  data, the bandwidth was chosen to be  0.25 Hz  ( dt  was chosen to be equal  2 s ). Consequently, the reference band frequency  fpo  is defined as  $$\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \n$$  O1  data thus contains  ${\\simeq} 2000$  narrow  0.25 Hz  bands in the frequency range  10-500 Hz . Because of the sampling time change, the total number of data points in the 2 sideral day long segment is  N=86164 . For lower frequencies 6 day length segments are used. They contain  N=258492  double-precision numbers.", 
            "title": "4.1 O1 change of sampling dt (bandwidth B) and data length"
        }, 
        {
            "location": "/search_for_candidates/#5-input-data-files", 
            "text": "A single run requires 2 data files for each detector  DD , stored in  data_dir/nnn/DD  \nsubdirectory, where  DD  is  H1  (Hanford),  L1  (Livingston), or  V1  (Virgo Cascina):    xdat_nnn_bbb.bin  - time-domain narrow-band data sequence, sampled\n     at  half second.  nnn  is the number of time frame,  bbb  is the\n     number of frequency band,    DetSSB.bin   -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in\n     Cartesian coordinates, sampled at half second (3dim array of size  N ). \n     Last two records\n     of  this file  are the angle  phir , determining the  position of\n     Earth in  its diurnal motion, and the obliquity of  the ecliptic\n      epsm , both calculated for the first sample of the data,    as we as the sky positions-frequency-spindown grid file in linear coordinates \n(common for all the detectors), stored in  data_dir/nnn :    grid.bin  - generator matrix of an optimal grid of templates.", 
            "title": "5. Input data files"
        }, 
        {
            "location": "/search_for_candidates/#6-output-files", 
            "text": "Binary output  files,   containing  trigger  events   above  an  arbitrary\nthreshold, are written to  the output_dir directory.  There are two output\nfiles for every input data sequence:  triggers_nnn_bbb_1.bin  and triggers_nnn_bbb_2.bin ,  where   1   and   2  correspond to  northern  and\nsouthern  ecliptic  hemisphere. Every trigger (candidate) event  occupies  40 \nconsecutive bytes (5 double numbers), with the following meaning:     Record no.       1  frequency [radians, between 0 and  $\\pi$ ] above  fpo    2  spindown [Hz s -1 ]    3  declination [radians]    4  right ascension [radians]    5  signal to noise ratio", 
            "title": "6. Output files"
        }, 
        {
            "location": "/search_for_candidates/#7-auxiliary-files", 
            "text": "There is a couple of auxiliary files created by the  search  \nin the working directory:    wisdom-hostname.dat  - \"wisdom\" file created by the  FFTW . The  hostname  \nvariable is determined by a call to  gethostname() ,     state_nnn_bbb.dat  - checkpoint file.  The  search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.", 
            "title": "7. Auxiliary files"
        }, 
        {
            "location": "/search_for_candidates/#8-versions", 
            "text": "Polgraw-allsky code comes also as an MPI , network of detectors spotlight\nsearch  and a GPU  version.", 
            "title": "8. Versions"
        }, 
        {
            "location": "/coincidences/", 
            "text": "Coincidences between candidates\n\n\nIn order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the \nF-statistic candidate signal search\n, the pipeline searches for coincidences between candidates found in different time frames. \n\n\nThe coincidences code is available at \ngithub\n. To get it, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n.\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. The only dependency is \nGNU Scientific Library (GSL)\n, used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues). \nGNU struct dirent\n objects are used to read the directories. \n\n\nThe idea behind coincidences\n\n\nAfter finding the candidate signals in different time frames (\nsearch\n), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the \nfollowup\n, currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file\n\n\n\n\na candidate is transformed to a well-defined time moment (frequency shifted to a reference frame), \n\n\ntranslated into linear (integer) coordinates, \n\n\nduplicates within each frame are removed, \n\n\nlist of unique candidates from all the frames is created and sorted, \n\n\nduplicates are counted - these are the coincidences. \n\n\n\n\n[-x----][-x----][-x----][-x----][-----y][-x----][-x----][---z--]\n6 coincidences of x in 8 data segments, not bad...\n\n\n\n\nTODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)\n \n\n\n7. Compilation\n\n\nRun \nmake coincidences\n; resulting binary is called \ncoincidences\n. Modify the \nMakefile\n to fit your system.\n\n\n8. How to run the program?\n\n\nSample call of \ncoincidences\n is as follows:\n\n\n ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2\n summary\n\n\n\n\nThis assumes that the 0666 band frequency \nfpo\n is 171.296875, since we define \n\n\nfpo = 10. + (1-2^(-5))*band*(0.5/dt) \n\n\n\n\nThe reference grid, corresponding to the reference frame 010 is located at \n-refloc\n location. Some output is directed to \nstdin\n. The highest-coincidence is outputed to \nstderr\n, redirected to a \nsummary\n file (\n2\n summary\n). In principle one has to run the code 16 times for all the \n$2^4$\n shifts \n0000--1111\n.   \n\n\n8.1. Full list of switches\n\n\nType \n\n\n ./coincidences --help \n\n\n\n\nto obtain the following description: \n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n./candidates\n)\n\n\n\n\n\n\n-output\n\n\nOutput directory (default is \n./coinc-results\n)\n\n\n\n\n\n\n-shift\n\n\nCell shifts in \nfsda\n directions (4 digit number, e.g. \n0101\n, default \n0000\n)\n\n\n\n\n\n\n-scale\n\n\nCell scaling in \nfsda\n directions (4 digit number, e.g. \n4824\n, default \n1111\n)\n\n\n\n\n\n\n-refr\n\n\nReference frame number\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-trigname\n\n\nPart of triggers' name (for identifying files)\n\n\n\n\n\n\n-refloc\n\n\nLocation of the reference grid.bin and starting_date files\n\n\n\n\n\n\n-mincoin\n\n\nMinimal number of coincidences recorded\n\n\n\n\n\n\n-narrowdown\n\n\nNarrow-down the frequency band (range [0, 0.5] +- around center)\n\n\n\n\n\n\n-snrcutoff\n\n\nSignal-to-noise threshold cutoff (default value: 6)\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\n9. Output\n\n\nOutput to the screen (\nstdout\n) in the case of \n\n\n ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2\n summary\n\n\n\n\nis\n\n\nThe SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at 6d_xdat_0.25/010\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 2152.580016\nReference frame number: 10\nCell shifts  in f, s, d, a directions: 0 1 1 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers_005_0666_2.bin... Frame 5: 941/1879\nReading triggers_019_0666_2.bin... Frame 19: 1320/1794\nReading triggers_003_0666_2.bin... Frame 3: 1512/1920\nReading triggers_008_0666_2.bin... Frame 8: 3090/6849\nReading triggers_002_0666_2.bin... Frame 2: 1014/1173\nReading triggers_014_0666_2.bin... Frame 14: 779/1542\nReading triggers_006_0666_2.bin... Frame 6: 2884/8822\nReading triggers_011_0666_2.bin... Frame 11: 918/2896\nTotal number of candidates from all frames: 12458\n\n\n\n\nThe highest-coincidence is streamed to a \nsummary\n file via \nstderr\n:  \n\n\n cat summary \ntriggers_ 0110 171.296875 8 8 1.05795986e+00 -7.69412393e-09 -7.42581733e-01 5.39896106e+00 2.417267e+01 5 1879 941 19 1794 1320 3 1920 1512 8 6849 3090 2 1173 1014 14 1542 779 6 8822 2884 11 2896 918\n\n\n\n\nIt contains the \ntrigname\n identifier, the \nshift\n value, the \nfpo\n band frequency, the number of files read (8), and the highest coincidence found (8). Next 5 numbers are arithmetic mean values of the frequency \n$\\,f$\n (in radians), frequency derivative \n$\\,\\dot{f}$\n (spindown), sky positions \n$\\delta$\n and \n$\\alpha$\n, and the mean signal-to-noise ratio, \n$\\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2}$\n. The following integers are grouped in threes and denote the triggers/time frame number, number of all candidates in that triggers' file, and the number of unique candidates. \n\n\nCoincidences above \nmincoin\n are recorded in a binary file \n.coi\n, separately for each shift, in the \n-output\n directory. Each coincidence is a set of following numbers: \n\n$$\nN,\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{d},\\quad\\bar{a},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N}\n$$\n\nwhere \n\n\n\n\n$N$\n is the size of coincidence (written as one \nunsigned short int\n), \n\n\n$\\bar{f}$\n, \n$\\bar{s}$\n, \n$\\bar{d}$\n, \n$\\bar{a}$\n and \n$\\widetilde{\\mathrm{snr}}$\n are the mean parameters of the signal (\n$5\\times$\nfloat\n),\n\n\n$\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N}$\n are the frame numbers (\n$N\\times$\nunsigned short int\n), \n\n\n$\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N}$\n are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files (\n$N\\times$\nint\n).", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#coincidences-between-candidates", 
            "text": "In order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the  F-statistic candidate signal search , the pipeline searches for coincidences between candidates found in different time frames.   The coincidences code is available at  github . To get it, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#prerequisites", 
            "text": "The code is written in standard  C . The only dependency is  GNU Scientific Library (GSL) , used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues).  GNU struct dirent  objects are used to read the directories.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/coincidences/#the-idea-behind-coincidences", 
            "text": "After finding the candidate signals in different time frames ( search ), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the  followup , currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file   a candidate is transformed to a well-defined time moment (frequency shifted to a reference frame),   translated into linear (integer) coordinates,   duplicates within each frame are removed,   list of unique candidates from all the frames is created and sorted,   duplicates are counted - these are the coincidences.    [-x----][-x----][-x----][-x----][-----y][-x----][-x----][---z--]\n6 coincidences of x in 8 data segments, not bad...  TODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)", 
            "title": "The idea behind coincidences"
        }, 
        {
            "location": "/coincidences/#7-compilation", 
            "text": "Run  make coincidences ; resulting binary is called  coincidences . Modify the  Makefile  to fit your system.", 
            "title": "7. Compilation"
        }, 
        {
            "location": "/coincidences/#8-how-to-run-the-program", 
            "text": "Sample call of  coincidences  is as follows:   ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2  summary  This assumes that the 0666 band frequency  fpo  is 171.296875, since we define   fpo = 10. + (1-2^(-5))*band*(0.5/dt)   The reference grid, corresponding to the reference frame 010 is located at  -refloc  location. Some output is directed to  stdin . The highest-coincidence is outputed to  stderr , redirected to a  summary  file ( 2  summary ). In principle one has to run the code 16 times for all the  $2^4$  shifts  0000--1111 .", 
            "title": "8. How to run the program?"
        }, 
        {
            "location": "/coincidences/#81-full-list-of-switches", 
            "text": "Type    ./coincidences --help   to obtain the following description:      Switch  Description      -data  Data directory (default is  ./candidates )    -output  Output directory (default is  ./coinc-results )    -shift  Cell shifts in  fsda  directions (4 digit number, e.g.  0101 , default  0000 )    -scale  Cell scaling in  fsda  directions (4 digit number, e.g.  4824 , default  1111 )    -refr  Reference frame number    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -trigname  Part of triggers' name (for identifying files)    -refloc  Location of the reference grid.bin and starting_date files    -mincoin  Minimal number of coincidences recorded    -narrowdown  Narrow-down the frequency band (range [0, 0.5] +- around center)    -snrcutoff  Signal-to-noise threshold cutoff (default value: 6)     Also:           --help  This help", 
            "title": "8.1. Full list of switches"
        }, 
        {
            "location": "/coincidences/#9-output", 
            "text": "Output to the screen ( stdout ) in the case of    ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2  summary  is  The SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at 6d_xdat_0.25/010\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 2152.580016\nReference frame number: 10\nCell shifts  in f, s, d, a directions: 0 1 1 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers_005_0666_2.bin... Frame 5: 941/1879\nReading triggers_019_0666_2.bin... Frame 19: 1320/1794\nReading triggers_003_0666_2.bin... Frame 3: 1512/1920\nReading triggers_008_0666_2.bin... Frame 8: 3090/6849\nReading triggers_002_0666_2.bin... Frame 2: 1014/1173\nReading triggers_014_0666_2.bin... Frame 14: 779/1542\nReading triggers_006_0666_2.bin... Frame 6: 2884/8822\nReading triggers_011_0666_2.bin... Frame 11: 918/2896\nTotal number of candidates from all frames: 12458  The highest-coincidence is streamed to a  summary  file via  stderr :     cat summary \ntriggers_ 0110 171.296875 8 8 1.05795986e+00 -7.69412393e-09 -7.42581733e-01 5.39896106e+00 2.417267e+01 5 1879 941 19 1794 1320 3 1920 1512 8 6849 3090 2 1173 1014 14 1542 779 6 8822 2884 11 2896 918  It contains the  trigname  identifier, the  shift  value, the  fpo  band frequency, the number of files read (8), and the highest coincidence found (8). Next 5 numbers are arithmetic mean values of the frequency  $\\,f$  (in radians), frequency derivative  $\\,\\dot{f}$  (spindown), sky positions  $\\delta$  and  $\\alpha$ , and the mean signal-to-noise ratio,  $\\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2}$ . The following integers are grouped in threes and denote the triggers/time frame number, number of all candidates in that triggers' file, and the number of unique candidates.   Coincidences above  mincoin  are recorded in a binary file  .coi , separately for each shift, in the  -output  directory. Each coincidence is a set of following numbers:  $$\nN,\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{d},\\quad\\bar{a},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N}\n$$ \nwhere    $N$  is the size of coincidence (written as one  unsigned short int ),   $\\bar{f}$ ,  $\\bar{s}$ ,  $\\bar{d}$ ,  $\\bar{a}$  and  $\\widetilde{\\mathrm{snr}}$  are the mean parameters of the signal ( $5\\times$ float ),  $\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N}$  are the frame numbers ( $N\\times$ unsigned short int ),   $\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N}$  are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files ( $N\\times$ int ).", 
            "title": "9. Output"
        }, 
        {
            "location": "/pipeline_script/", 
            "text": "Pipeline: search for candidate signals and coincidences among them\n\n\n1. Sample PBS/Torque script\n\n\nThis is a sample \npipeline.sh\n script for the spotlight version of the \nsearch\n code, designed to look for signal around a specific location given by the spotlight range data file for 2-day narrow-band data segments. After the candidate signals are found, the search for coincidences is performed. It is currently used in the Mock Data Challenge with injected signals.  \n\n\nThis script uses a lower threshold (option \n-t 10\n) while searching for candidate signals, looks for coincidences in a \n[4 4 4 4]\n cell (see options to \ncoiproc\n) and prepares the summary of the estimation (\nsummary\n file) at the end of execution. The binary files \n*.coi\n - results of coincidences - are archived with the \nlz4.gz\n (\nlz4\n) compression to save space, and deleted after the coincidences procedure is done.  \n\n\n#!/bin/bash \n#PBS -m n \n#PBS -j oe\n#PBS -q medium\n#PBS -l walltime=48:00:00\n\n# Data directory \ndata=/work/psk/bejger/mdc/pulsar-data\n# Candidate (triggers) files output directory \ncandout=/work/psk/bejger/mdc/cand-mdcthr10_$FILENUM\n\n# Directory with coincidence codes \ncoisrc=/work/psk/bejger/mdc/coincidences-codes-binary\n# Coincidences output directory \ncoiout=/work/psk/bejger/mdc/coin-mdcthr10_$FILENUM\n\n# Path to the libraries (in the src/lib directory of the search code)\nldlp=/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n# Path to lz4 compressor\nlz4path=/work/psk/bejger/codes/lz4-r131/programs\n\ncd $PBS_O_WORKDIR\n\nwhile read line; do\n\n  # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n  # the master file is mdc_1561pulsars (name fpo f_gw) \n  name=$(echo $line | awk '{print $1}')\n  fgw=$(echo $line | awk '{print $3}')\n  fpo=$(echo $line | awk '{print $2}')\n\n  #-----------------------\n  # Search for candidates \n  #-----------------------\n  echo $name $(date +%H:%M:%S) \ncandidate search\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n  # search in frames xxx -- yyy  \n  for i in $(seq -f %03g 1 210); do\n\n    # spotlight file range location \n    spoth1=${data}/${i}/H1/spot_${name}.dat\n    spotl1=${data}/${i}/L1/spot_${name}.dat\n\n    # Here we assume that both H1 and L1 data is present for segment $i, \n    # and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n    # it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n    # If both $spoth1 and $spotl1 are missing, it means there is no good data \n    # and the code exits (since there is nothing to analyze).\n\n    spotfile=''\n    if [ -f $spoth1 ]; then spotfile=$spoth1 \n    else spotfile=$spotl1\n    fi \n\n    # threshold is set to -threshold 10\n    LD_LIBRARY_PATH=$ldlp ./search -data $data -ident $i -band 000 --nocheckpoint -output $candout -spotlight $spotfile -fpo $fpo -label $name -dt 2 -threshold 10 1\n $name.$PBS_JOBID.out 2\n $name.$PBS_JOBID.err\n\n  done \n\n  #------------------------------------------ \n  # Search for coincidences among candidates \n  #------------------------------------------\n  echo $name $(date +%H:%M:%S) \ncoincidences\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n\n  mkdir -p $coiout/$name; cd $coiout/$name\n\n  # Copying the trigger files to the working directory \n  cp $candout/triggers*${name}*.bin .\n\n  # Name for the list of files \n  st=$(ls triggers*${name}*.bin | tail -1); listfile=${st: -16:10}'_000'${st: -6:2}'.list';\n  echo \nName for the list of files: \n $listfile \n\n  echo \nRemoving the name of the pulsar from the triggers' files...\n\n  for f in $(ls triggers_*.bin); do mv $f ${f:0:16}${f: -6:6}; done\n\n  echo \nVetoing: processing the triggers' files...\n \n  for f in $(ls triggers_*.bin); do \n    $coisrc/trigveto -noveto -fpo $fpo $f  \n    # Removing original triggers files \n    rm $f \n  done \n\n  echo \nRemoving candidates outside a narrow frequency band (+- 0.05)...\n\n  for f in $(ls pvc_*.bin); do\n    $coisrc/decym $f $fgw 0.05\n  done\n\n  echo \nWriting list of pvc files to \n $listfile \n  ls pvc_*.bin \n $listfile\n\n  echo \nSearching for coincidences...\n \n  for i in {0..1}{0..1}{0..1}{0..1}; do \n    $coisrc/coiproc -binary -refr 100 -scale_f 4 -scale_s 4 -scale_a 4 -scale_d 4 -shift $i -fpo $fpo $listfile \n  done\n\n  echo \nGenerating the stat file...\n \n  st=$(grep \nMax value\n *.resf | sort -gk 5 | tail -1)\n  mcoi=$(echo $st | awk '{print $5}')\n  resf=$(echo $st | awk '{print $1}')\n  resf=${resf:0:10} \n  $coisrc/resf2stat -threshold $mcoi -binary $resf \n\n  echo \nEstimating the parameters...\n\n  $coisrc/stat2data -threshold $mcoi -refr 100 . *.stat\n\n  echo \nPreparing the summary...\n \n  st=$(find . -name \n*.stat.dat\n -printf '%f\\n')\n  if [ -z $st ]; then\n    echo $name $fpo \nno coincidences\n \n ../summary\n  else\n    echo $name $fpo $(wc -l \n $listfile) $(awk 'END{printf \n%20s %.9e %.9e %.9e %.9e %.9e\n,FILENAME,$3,$4,$5,$6,$7}' $st) \n ../summary\n  fi \n\n  # Cleanup (archiving and deleting the coi files) \n  echo $name $(date +%H:%M:%S) \narchiving coi files\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n  for r in $(ls *.coi); do \n    ${lz4path}/lz4 -6 ${r} ${r}.lz4 \n gzip ${r}.lz4\n    if [ -f ${r}\n.lz4.gz\n ]; then \n      rm $r\n    fi \n  done \n\n  cd $PBS_O_WORKDIR\n\n  echo $name $(date +%H:%M:%S) \nend\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\ndone \n pulsar_file_$FILENUM\n\nexit 0\n\n\n\n\nwhere the \npulsar_file_$FILENUM\n contains 3 columns: pulsar \nname\n, \nfpo\n reference frequency and gravitational wave frequency of the pulsar \nfgw\n. For an exemplary \npulsar_file_666\n, contaning 8 pulsars,  \n\n\nJ0440+6416 516.601562 516.721000\nJ0714-6355 538.630859 538.755400\nJ0424+3800 561.185547 561.302200\nJ0303-5616 1089.595703 1089.719400\nJ0612+3324 390.177734 390.297600\nJ0319-7629 466.138672 466.263800\nJ0803-6214 1700.154297 1700.281800\nJ0534+0935 258.660156 258.781000\n\n\n\n\nthe job can be sent to the PBS queue in the following way:  \n\n\nqsub -v FILENUM=666 -N mdc-666 pipeline.sh\n\n\n\n\n2. Sample PBS/Torque script using the \nC\n coincidences code\n\n\n#!/bin/bash \n#PBS -m n \n#PBS -j oe\n#PBS -q medium\n#PBS -l mem=2GB\n#PBS -l walltime=04:00:00\n\n# Data directory \ndata=/work/psk/bejger/mdc/pulsar-data\n# Candidate (triggers) files output directory \ncandout=/work/psk/bejger/mdc/candidates-mdc-thr10\n\n# Directory with coincidence codes \ncoisrc=/work/psk/bejger/mdc/ccoin\n# Coincidences output directory \ncoiout=/work/psk/bejger/mdc/coin-mdcthr10\n\n# Path to the libraries (in the src/lib directory of the search code)\nldlp=/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n# Path to lz4 compressor\nlz4path=/work/psk/bejger/codes/lz4-r131/programs\n\ncd $PBS_O_WORKDIR\n\nwhile read line; do\n\n  # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n  # the master file is mdc_1561pulsars (name fpo f_gw) \n  name=$(echo $line | awk '{print $1}')\n  fgw=$(echo $line | awk '{print $3}')\n  fpo=$(echo $line | awk '{print $2}')\n\n  #-----------------------\n  # Search for candidates \n  #-----------------------\n  echo $name $(date +%H:%M:%S) \ncandidate search\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n  # search in frames xxx -- yyy  \n  for i in $(seq -f %03g 1 210); do\n\n    # spotlight file range location \n    spoth1=${data}/${i}/H1/spot_${name}.dat\n    spotl1=${data}/${i}/L1/spot_${name}.dat\n\n    # Here we assume that both H1 and L1 data is present for segment $i, \n    # and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n    # it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n    # If both $spoth1 and $spotl1 are missing, it means there is no good data \n    # and the code exits (since there is nothing to analyze).\n\n    spotfile=''\n    if [ -f $spoth1 ]; then spotfile=$spoth1 \n    else spotfile=$spotl1\n    fi \n\n    # threshold is set to -threshold 10\n    LD_LIBRARY_PATH=$ldlp ./search -data $data -ident $i -band 000 --nocheckpoint -output $candout -spotlight $spotfile -fpo $fpo -label $name -dt 2 -threshold 10 1\n $name.$PBS_JOBID.out 2\n $name.$PBS_JOBID.err\n\n  done \n\n  #------------------------------------------ \n  # Search for coincidences among candidates \n  #------------------------------------------\n  echo $name $(date +%H:%M:%S) \ncoinc: start\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n  # Creating a directory for each pulsar coincidence files \n  mkdir -p $coiout/$name\n\n  # Searching for coincidences \n  for shi in {0..1}{0..1}{0..1}{0..1}; do\n    ./coincidences -data $candout -trigname $name -refloc ${coisrc}/coinc-testdata -fpo $fpo -shift $shi -scale 4444 -refr 100 -dt 2 -mincoin 15 -narrowdown 0.2 -output ${coiout}/${name} 2\n ${coiout}/${name}/summary 1\n /dev/null  \n  done\n\n  # Selecting maximal coincidence among all 16 shifts (col. 5) \n  # If many, select the one with highest SNR (col. 10)  \n  sort -rgk5 -gk10 ${coiout}/${name}/summary | head -1 \n ${coiout}/summary \n\n  #------------------------------------------ \n  # Cleanup \n  #------------------------------------------\n\n  echo $name $(date +%H:%M:%S) \ncoinc: archiving coi files\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\n  for r in $(ls ${coiout}/${name}/*.coi); do \n    ${lz4path}/lz4 -6 ${r} ${r}.lz4 \n gzip ${r}.lz4\n    if [ -f ${r}\n.lz4.gz\n ]; then \n      rm $r\n    fi \n  done \n\n  echo $name $(date +%H:%M:%S) \ncoinc: end\n \n $PBS_O_WORKDIR/timing_$FILENUM\n\ndone \n pulsar_file_$FILENUM\n\nexit 0", 
            "title": "Pipeline script"
        }, 
        {
            "location": "/pipeline_script/#pipeline-search-for-candidate-signals-and-coincidences-among-them", 
            "text": "", 
            "title": "Pipeline: search for candidate signals and coincidences among them"
        }, 
        {
            "location": "/pipeline_script/#1-sample-pbstorque-script", 
            "text": "This is a sample  pipeline.sh  script for the spotlight version of the  search  code, designed to look for signal around a specific location given by the spotlight range data file for 2-day narrow-band data segments. After the candidate signals are found, the search for coincidences is performed. It is currently used in the Mock Data Challenge with injected signals.    This script uses a lower threshold (option  -t 10 ) while searching for candidate signals, looks for coincidences in a  [4 4 4 4]  cell (see options to  coiproc ) and prepares the summary of the estimation ( summary  file) at the end of execution. The binary files  *.coi  - results of coincidences - are archived with the  lz4.gz  ( lz4 ) compression to save space, and deleted after the coincidences procedure is done.    #!/bin/bash \n#PBS -m n \n#PBS -j oe\n#PBS -q medium\n#PBS -l walltime=48:00:00\n\n# Data directory \ndata=/work/psk/bejger/mdc/pulsar-data\n# Candidate (triggers) files output directory \ncandout=/work/psk/bejger/mdc/cand-mdcthr10_$FILENUM\n\n# Directory with coincidence codes \ncoisrc=/work/psk/bejger/mdc/coincidences-codes-binary\n# Coincidences output directory \ncoiout=/work/psk/bejger/mdc/coin-mdcthr10_$FILENUM\n\n# Path to the libraries (in the src/lib directory of the search code)\nldlp=/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n# Path to lz4 compressor\nlz4path=/work/psk/bejger/codes/lz4-r131/programs\n\ncd $PBS_O_WORKDIR\n\nwhile read line; do\n\n  # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n  # the master file is mdc_1561pulsars (name fpo f_gw) \n  name=$(echo $line | awk '{print $1}')\n  fgw=$(echo $line | awk '{print $3}')\n  fpo=$(echo $line | awk '{print $2}')\n\n  #-----------------------\n  # Search for candidates \n  #-----------------------\n  echo $name $(date +%H:%M:%S)  candidate search    $PBS_O_WORKDIR/timing_$FILENUM\n\n  # search in frames xxx -- yyy  \n  for i in $(seq -f %03g 1 210); do\n\n    # spotlight file range location \n    spoth1=${data}/${i}/H1/spot_${name}.dat\n    spotl1=${data}/${i}/L1/spot_${name}.dat\n\n    # Here we assume that both H1 and L1 data is present for segment $i, \n    # and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n    # it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n    # If both $spoth1 and $spotl1 are missing, it means there is no good data \n    # and the code exits (since there is nothing to analyze).\n\n    spotfile=''\n    if [ -f $spoth1 ]; then spotfile=$spoth1 \n    else spotfile=$spotl1\n    fi \n\n    # threshold is set to -threshold 10\n    LD_LIBRARY_PATH=$ldlp ./search -data $data -ident $i -band 000 --nocheckpoint -output $candout -spotlight $spotfile -fpo $fpo -label $name -dt 2 -threshold 10 1  $name.$PBS_JOBID.out 2  $name.$PBS_JOBID.err\n\n  done \n\n  #------------------------------------------ \n  # Search for coincidences among candidates \n  #------------------------------------------\n  echo $name $(date +%H:%M:%S)  coincidences    $PBS_O_WORKDIR/timing_$FILENUM\n\n\n  mkdir -p $coiout/$name; cd $coiout/$name\n\n  # Copying the trigger files to the working directory \n  cp $candout/triggers*${name}*.bin .\n\n  # Name for the list of files \n  st=$(ls triggers*${name}*.bin | tail -1); listfile=${st: -16:10}'_000'${st: -6:2}'.list';\n  echo  Name for the list of files:   $listfile \n\n  echo  Removing the name of the pulsar from the triggers' files... \n  for f in $(ls triggers_*.bin); do mv $f ${f:0:16}${f: -6:6}; done\n\n  echo  Vetoing: processing the triggers' files...  \n  for f in $(ls triggers_*.bin); do \n    $coisrc/trigveto -noveto -fpo $fpo $f  \n    # Removing original triggers files \n    rm $f \n  done \n\n  echo  Removing candidates outside a narrow frequency band (+- 0.05)... \n  for f in $(ls pvc_*.bin); do\n    $coisrc/decym $f $fgw 0.05\n  done\n\n  echo  Writing list of pvc files to   $listfile \n  ls pvc_*.bin   $listfile\n\n  echo  Searching for coincidences...  \n  for i in {0..1}{0..1}{0..1}{0..1}; do \n    $coisrc/coiproc -binary -refr 100 -scale_f 4 -scale_s 4 -scale_a 4 -scale_d 4 -shift $i -fpo $fpo $listfile \n  done\n\n  echo  Generating the stat file...  \n  st=$(grep  Max value  *.resf | sort -gk 5 | tail -1)\n  mcoi=$(echo $st | awk '{print $5}')\n  resf=$(echo $st | awk '{print $1}')\n  resf=${resf:0:10} \n  $coisrc/resf2stat -threshold $mcoi -binary $resf \n\n  echo  Estimating the parameters... \n  $coisrc/stat2data -threshold $mcoi -refr 100 . *.stat\n\n  echo  Preparing the summary...  \n  st=$(find . -name  *.stat.dat  -printf '%f\\n')\n  if [ -z $st ]; then\n    echo $name $fpo  no coincidences    ../summary\n  else\n    echo $name $fpo $(wc -l   $listfile) $(awk 'END{printf  %20s %.9e %.9e %.9e %.9e %.9e ,FILENAME,$3,$4,$5,$6,$7}' $st)   ../summary\n  fi \n\n  # Cleanup (archiving and deleting the coi files) \n  echo $name $(date +%H:%M:%S)  archiving coi files    $PBS_O_WORKDIR/timing_$FILENUM\n\n  for r in $(ls *.coi); do \n    ${lz4path}/lz4 -6 ${r} ${r}.lz4   gzip ${r}.lz4\n    if [ -f ${r} .lz4.gz  ]; then \n      rm $r\n    fi \n  done \n\n  cd $PBS_O_WORKDIR\n\n  echo $name $(date +%H:%M:%S)  end    $PBS_O_WORKDIR/timing_$FILENUM\n\ndone   pulsar_file_$FILENUM\n\nexit 0  where the  pulsar_file_$FILENUM  contains 3 columns: pulsar  name ,  fpo  reference frequency and gravitational wave frequency of the pulsar  fgw . For an exemplary  pulsar_file_666 , contaning 8 pulsars,    J0440+6416 516.601562 516.721000\nJ0714-6355 538.630859 538.755400\nJ0424+3800 561.185547 561.302200\nJ0303-5616 1089.595703 1089.719400\nJ0612+3324 390.177734 390.297600\nJ0319-7629 466.138672 466.263800\nJ0803-6214 1700.154297 1700.281800\nJ0534+0935 258.660156 258.781000  the job can be sent to the PBS queue in the following way:    qsub -v FILENUM=666 -N mdc-666 pipeline.sh", 
            "title": "1. Sample PBS/Torque script"
        }, 
        {
            "location": "/pipeline_script/#2-sample-pbstorque-script-using-the-c-coincidences-code", 
            "text": "#!/bin/bash \n#PBS -m n \n#PBS -j oe\n#PBS -q medium\n#PBS -l mem=2GB\n#PBS -l walltime=04:00:00\n\n# Data directory \ndata=/work/psk/bejger/mdc/pulsar-data\n# Candidate (triggers) files output directory \ncandout=/work/psk/bejger/mdc/candidates-mdc-thr10\n\n# Directory with coincidence codes \ncoisrc=/work/psk/bejger/mdc/ccoin\n# Coincidences output directory \ncoiout=/work/psk/bejger/mdc/coin-mdcthr10\n\n# Path to the libraries (in the src/lib directory of the search code)\nldlp=/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n# Path to lz4 compressor\nlz4path=/work/psk/bejger/codes/lz4-r131/programs\n\ncd $PBS_O_WORKDIR\n\nwhile read line; do\n\n  # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n  # the master file is mdc_1561pulsars (name fpo f_gw) \n  name=$(echo $line | awk '{print $1}')\n  fgw=$(echo $line | awk '{print $3}')\n  fpo=$(echo $line | awk '{print $2}')\n\n  #-----------------------\n  # Search for candidates \n  #-----------------------\n  echo $name $(date +%H:%M:%S)  candidate search    $PBS_O_WORKDIR/timing_$FILENUM\n\n  # search in frames xxx -- yyy  \n  for i in $(seq -f %03g 1 210); do\n\n    # spotlight file range location \n    spoth1=${data}/${i}/H1/spot_${name}.dat\n    spotl1=${data}/${i}/L1/spot_${name}.dat\n\n    # Here we assume that both H1 and L1 data is present for segment $i, \n    # and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n    # it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n    # If both $spoth1 and $spotl1 are missing, it means there is no good data \n    # and the code exits (since there is nothing to analyze).\n\n    spotfile=''\n    if [ -f $spoth1 ]; then spotfile=$spoth1 \n    else spotfile=$spotl1\n    fi \n\n    # threshold is set to -threshold 10\n    LD_LIBRARY_PATH=$ldlp ./search -data $data -ident $i -band 000 --nocheckpoint -output $candout -spotlight $spotfile -fpo $fpo -label $name -dt 2 -threshold 10 1  $name.$PBS_JOBID.out 2  $name.$PBS_JOBID.err\n\n  done \n\n  #------------------------------------------ \n  # Search for coincidences among candidates \n  #------------------------------------------\n  echo $name $(date +%H:%M:%S)  coinc: start    $PBS_O_WORKDIR/timing_$FILENUM\n\n  # Creating a directory for each pulsar coincidence files \n  mkdir -p $coiout/$name\n\n  # Searching for coincidences \n  for shi in {0..1}{0..1}{0..1}{0..1}; do\n    ./coincidences -data $candout -trigname $name -refloc ${coisrc}/coinc-testdata -fpo $fpo -shift $shi -scale 4444 -refr 100 -dt 2 -mincoin 15 -narrowdown 0.2 -output ${coiout}/${name} 2  ${coiout}/${name}/summary 1  /dev/null  \n  done\n\n  # Selecting maximal coincidence among all 16 shifts (col. 5) \n  # If many, select the one with highest SNR (col. 10)  \n  sort -rgk5 -gk10 ${coiout}/${name}/summary | head -1   ${coiout}/summary \n\n  #------------------------------------------ \n  # Cleanup \n  #------------------------------------------\n\n  echo $name $(date +%H:%M:%S)  coinc: archiving coi files    $PBS_O_WORKDIR/timing_$FILENUM\n\n  for r in $(ls ${coiout}/${name}/*.coi); do \n    ${lz4path}/lz4 -6 ${r} ${r}.lz4   gzip ${r}.lz4\n    if [ -f ${r} .lz4.gz  ]; then \n      rm $r\n    fi \n  done \n\n  echo $name $(date +%H:%M:%S)  coinc: end    $PBS_O_WORKDIR/timing_$FILENUM\n\ndone   pulsar_file_$FILENUM\n\nexit 0", 
            "title": "2. Sample PBS/Torque script using the C coincidences code"
        }, 
        {
            "location": "/articles/", 
            "text": "List of documents and publications\n\n\nArticles\n\n\n\n\nData analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search\n \n(arXiv)\n\n\nImplementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data\n \n(arXiv)\n\n\n\n\nResonant bar detectors\n\n\n\n\nAll-sky search of NAUTILUS data\n \n(arXiv)\n\n\nAll-sky upper limit for gravitational radiation from spinning neutron stars\n \n(arXiv)\n\n\n\n\nMonographs\n\n\n\n\nGravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case\n\n\nAnalysis of Gravitational-Wave Data", 
            "title": "Literature"
        }, 
        {
            "location": "/articles/#list-of-documents-and-publications", 
            "text": "", 
            "title": "List of documents and publications"
        }, 
        {
            "location": "/articles/#articles", 
            "text": "Data analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search   (arXiv)  Implementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data   (arXiv)", 
            "title": "Articles"
        }, 
        {
            "location": "/articles/#resonant-bar-detectors", 
            "text": "All-sky search of NAUTILUS data   (arXiv)  All-sky upper limit for gravitational radiation from spinning neutron stars   (arXiv)", 
            "title": "Resonant bar detectors"
        }, 
        {
            "location": "/articles/#monographs", 
            "text": "Gravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case  Analysis of Gravitational-Wave Data", 
            "title": "Monographs"
        }
    ]
}