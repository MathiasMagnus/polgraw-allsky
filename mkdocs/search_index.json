{
    "docs": [
        {
            "location": "/", 
            "text": "Polgraw all-sky pipeline: search for almost monochromatic gravitational wave signals\n\n\nPipeline flowchart\n\n\n\n\n\n\n\n\n\n\nTopics\n\n\n\n\nInput data generation\n \n\n\nF-statistic candidate signal search\n\n\nCoincidences between candidates\n\n\nFalse alarm probability of coincidences\n \n\n\nPipeline: a minimal example\n\n\nDocuments and publications\n\n\n\n\nContributors\n\n\nIn alphabetic order:\n\n\n\n\nMicha\u0142 Bejger\n\n\nJan Bolek\n\n\nPawe\u0142 Cieciel\u0105g\n\n\nOrest Dorosh\n\n\nAleksander Garus\n\n\nAndrzej Kr\u00f3lak\n\n\nMaciej Pi\u0119tka\n\n\nGevorg Poghosyan\n\n\nMagdalena Sieniawska \n\n\nRafa\u0142 Skrzypiec", 
            "title": "Home"
        }, 
        {
            "location": "/#polgraw-all-sky-pipeline-search-for-almost-monochromatic-gravitational-wave-signals", 
            "text": "", 
            "title": "Polgraw all-sky pipeline: search for almost monochromatic gravitational wave signals"
        }, 
        {
            "location": "/#pipeline-flowchart", 
            "text": "", 
            "title": "Pipeline flowchart"
        }, 
        {
            "location": "/#topics", 
            "text": "Input data generation    F-statistic candidate signal search  Coincidences between candidates  False alarm probability of coincidences    Pipeline: a minimal example  Documents and publications", 
            "title": "Topics"
        }, 
        {
            "location": "/#contributors", 
            "text": "In alphabetic order:   Micha\u0142 Bejger  Jan Bolek  Pawe\u0142 Cieciel\u0105g  Orest Dorosh  Aleksander Garus  Andrzej Kr\u00f3lak  Maciej Pi\u0119tka  Gevorg Poghosyan  Magdalena Sieniawska   Rafa\u0142 Skrzypiec", 
            "title": "Contributors"
        }, 
        {
            "location": "/input_data/", 
            "text": "Input data generation\n\n\nextract_band\n\n\nThis program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").\n\n\nPrerequisites\n\n\nC compiller. Uses standard C libraries, \nlibm\n. Links to the PSS library (created by Pia Astone).\n\n\nHow to run it?\n\n\n extract_band \n input_file\n\n\n\n\n\nwhere \ninput_file\n is an ASCII file contaning the following rows:  \n\n\n\n\nMaximal number of SFT\n\n\nThe name of the output file\n\n\nThe list of SFT files\n\n\nThe frequency band in Hz\n\n\nThe width of frequency band in Hz\n\n\n\n\nfor example: \n\n\n100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1\n\n\n\n\n\nOutput\n\n\nExample output: \n\n\n% Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT\n\n\n% 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20\n\n\n% FFT number in the file; Beginning mjd days; Gps s; Gps ns;\n\n\n% 100 55099.5879745370 937922816 0\n\n \n4.59662571e+02\n  \n2.27630825e+01\n\n\n-\n3.50387007e+02\n \n-\n2.20005558e+02\n\n \n3.57587904e+02\n  \n1.01217077e+02\n\n \n1.74400486e+02\n  \n2.62086552e+02\n\n \n2.21804800e+02\n \n-\n5.20278366e+02\n\n\n-\n3.87826732e+02\n \n-\n1.55758978e+02\n\n\n\n\n\n\ngen2day\n description\n\n\n...", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#input-data-generation", 
            "text": "", 
            "title": "Input data generation"
        }, 
        {
            "location": "/input_data/#extract_band", 
            "text": "This program converts Short Fourier Transformation series to time series. \nWritten by Pia Astone (INFN, Physics Department of University of Rome \"La Sapienza\").", 
            "title": "extract_band"
        }, 
        {
            "location": "/input_data/#prerequisites", 
            "text": "C compiller. Uses standard C libraries,  libm . Links to the PSS library (created by Pia Astone).", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/input_data/#how-to-run-it", 
            "text": "extract_band   input_file  where  input_file  is an ASCII file contaning the following rows:     Maximal number of SFT  The name of the output file  The list of SFT files  The frequency band in Hz  The width of frequency band in Hz   for example:   100000\nJ0034+1612_2010-10-10.out\nJ0034+1612_2010-10-10.list\n718.2480\n1", 
            "title": "How to run it?"
        }, 
        {
            "location": "/input_data/#output", 
            "text": "Example output:   % Beginning freq- Band- Samples in one stretch- Subsampling factor- inter (overlapping, 2 if data were overlapped)- Frequency step- Scaling factor- ***The data are real and imag of the FFT  % 908.152344 0.250000 256 8192.000000 2  0.0009766 1.000000e-20  % FFT number in the file; Beginning mjd days; Gps s; Gps ns;  % 100 55099.5879745370 937922816 0 \n  4.59662571e+02    2.27630825e+01  - 3.50387007e+02   - 2.20005558e+02 \n  3.57587904e+02    1.01217077e+02 \n  1.74400486e+02    2.62086552e+02 \n  2.21804800e+02   - 5.20278366e+02  - 3.87826732e+02   - 1.55758978e+02", 
            "title": "Output"
        }, 
        {
            "location": "/input_data/#gen2day-description", 
            "text": "...", 
            "title": "gen2day description"
        }, 
        {
            "location": "/search_for_candidates/", 
            "text": "F-statistic candidate signal search\n\n\nProduction serial code for a network of detectors is available at \nhere\n. \nOpenMP\n version is at \nthis location\n. To get the whole pipeline, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n. \n\n\nAlgorithm flowchart\n\n\n\n\n\n\n1. Prerequisites\n\n\nThe code is written in standard \nC\n. \nGNU Scientific Library (GSL)\n and the \nFFTW library\n (version 3.0 or later) are needed to run the code. \nGNU struct dirent\n objects are used to read the directories. \n\n\nOptionally, \nSLEEF\n or \nYEPPP!\n, libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in \nsrc/lib\n. The choice which of these libraries to use has to be made at compilation time by modifying the \nMakefile\n. \n\n\n2. Compilation. Example for serial CPU code\n\n\nRun  \nmake gwsearch-cpu\n or \nmake\n in \nsearch/network/src-cpu\n (default \nC\n version not-optimized with \nopenMP\n; for the \nopenMP\n version see the \nsearch/network/src-openmp\n directory). Resulting  binary is called \ngwsearch-cpu\n. Modify the \nMakefile\n to fit your system. By default the \nYEPPP!\n library is selected. \n\n\n3. How to run the program?\n\n\nMinimal call to \ngwsearch-cpu\n is as follows (code compiled with the \nGNUSINCOS\n option): \n\n\n./gwsearch-cpu -data data_dir -dt 2 -output output_dir -ident frame -band band\n\n\n\n\n\nwhere\n\n\n\n\ndata_dir\n is the base directory of input data files,\n\n\nSampling time \ndt\n is 2 (seconds), \n\n\noutput_dir\nis a directory to write the output,\n\n\nframe\n is the number of time frame to be analyzed,\n\n\nband\n is the number of the frequency band (see the \ndata structure\n description for details). \n\n\n\n\n\n\n3.1. Full list of switches\n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n.\n)\n\n\n\n\n\n\n-output\n\n\nOutput directory (default is \n./candidates\n)\n\n\n\n\n\n\n-ident\n\n\nFrame number\n\n\n\n\n\n\n-band\n\n\nBand number\n\n\n\n\n\n\n-label\n\n\nCustom label for the input and output files\n\n\n\n\n\n\n-range\n\n\nUse file with grid range or pulsar position\n\n\n\n\n\n\n-getrange\n\n\nWrite grid ranges \n save fft wisdom \n exit (ignore -r)\n\n\n\n\n\n\n-cwd\n\n\nChange to directory \ndir\n\n\n\n\n\n\n-threshold\n\n\nThreshold for the F-statistic (default is \n20\n)\n\n\n\n\n\n\n-hemisphere\n\n\nHemisphere (default is 0 - does both)\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-usedet\n\n\nUse only detectors from string (default is \nuse all available\n)\n\n\n\n\n\n\n-addsig\n\n\nAdd signal with parameters from \nfile\n\n\n\n\n\n\n-narrowdown\n\n\nNarrow-down the frequency band (range \n[0, 0.5] +- around center\n)\n\n\n\n\n\n\n\n\nAlso: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--whitenoise\n\n\nWhite Gaussian noise assumed\n\n\n\n\n\n\n--nospindown\n\n\nSpindowns neglected\n\n\n\n\n\n\n--nocheckpoint\n\n\nState file will not be created (no checkpointing)\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\n3.2. Network of detectors\n\n\nFor the examplary input data time streams \nxdatc_001_0101.bin\n provided in \ntest-data-network.tar.gz\n, the call is as follows:\n\n\nLD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu -data ./test-data-network -dt 2 -ident 001 -band 0101 -usedet H1V1 --nocheckpoint \n\n\n\n\n\nwhere the \nLD_LIBRARY_PATH\n points to the location of the \nYEPPP!\n library. \n\n\nThe program will proceed assuming that the data directory \n./test-data-network/001\n for the time frame \n001\n contain subdirectories for the network of detectors (here \nH1\n and \nV1\n) with input time series \nxdatc_001_0101.bin\n and the ephemerids files \nDetSSB.bin\n in each subdirectory, with the sampling time \ndt\n equal 2 seconds. The grid of parameters files is expected to be in \n./test-data-network/001/grid.bin\n. Switch \n-usedet H1\n (\n-usedet V1\n) select the appropriate data and performs single detector search. The \n--nocheckpoint\n disables the checkpointing (writing the last visited position on the grid to the \nstate\n file).   \n\n\n\n\n3.3. Network of detectors in spotlight search (depreciated)\n\n\nFor the \nH1L1\n network of detectors, using the \ntest-data-network-injection.tar.gz\n to search towards a pre-defined direction (spotlight search) in one 2-day segment:\n\n\nLD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./search -data ./test-data-network-injection -ident 205 -band 000 -spotlight ./test-data-network-injection/205/spot_J0322+0441.dat -fpo 1391.3 -label J0322+0441 -dt 2  \n\n\n\n\n\nThe injection corresponds to a pulsar J0322+0441. Note the differences with respect to the minimal call: \n\n\n\n\ninstead of calculating the band frequency \nfpo\n from \nband\n, we provide it directly with the \n-fpo\n switch (\n-band 000\n is invoked for legacy), \n\n\nthe input data is denoted with the pulsar label, hence the \n-label\n switch, \n\n\nthe sampling time \ndt\n is now set to \n2 s\n,\n\n\n-spotlight\n switch points to the location of the spotlight file which contains the list of sky positions, and corresponding number and values of spindowns, in the following format: \n\n\\begin{equation} \nh\\, N_{sky}\\, m_1\\, n_1\\, N^s_{1}\\, s_{1}\\, \\dots\\, s_{N^s_1}\\, \nm_2\\, n_2\\, N^s_{2}\\, s_1\\, \\dots\\, s_{N^s_2}\\, \\dots,  \n\\end{equation}\n \nwhere \nh\n is the hemisphere number (1 or 2), \nN_{sky}\n is the total number of sky positions in a given spotlight search, \nm_i\n and \nn_i\n are the sky positions in linear (grid) coordinates, \nN^s_{i}\n is the number of spindowns, and \ns_{i}\\,\\dots\\, s_{N^s_i}\n and the spindowns (in linear coordinates), corresponding to the \ni-\nth sky position.    \n\n\n\n\nResults are as follows: \n\n\n\n\n3.4. One-detector version\n\n\nIn the case of \none-detector\n version, test data is in \ntest-data.tar.gz\n. The directory \n001\n contains directly the \nDetSSB.bin\n, \ngrid.bin\n and \nxdatc_001_101.bin\n files. \n\n\n4. Data structure\n\n\n \nWe describe the structure using the VSR1 data as an example. \nTime of the first sample in MJD (Modified Julian Date) is 54239.00 \n(corresponding to 2007/05/18, UTC 12:00). \n\n\nIn this run the data was divided into 68 time frames, each of them 2 \nsideral  days  long, rounded to half second (172328 seconds each). \nSince we use the sampling time of \n0.5s\n, total number of data points \nin each time frame is \nN=344656\n. \n\n\nFrames are labelled with three-digit consecutive number, \nfrom \n001\n to \n068\n. Frame label is the name of a subfolder, containing \nall narrowband sequences corresponding to that frame, e.g., \n./042\n.\n\n\nBeginning MJD of each time frame is saved in the \nnnn/starting_date\n \nfile:\n\n\n   \n% cat 042/starting_date\n\n   \n54320.7760185185\n\n\n\n\n\n\nReference band frequency \nfpo\n is defined for each band as \n\n \nfpo = 100 + (1 - 2^{-5})\\cdot bbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]},\n\n\nwhere \nbbb\n is the band number, and \ndt\n is the data sampling time (\n0.5 s\n for VSR1 data). \n\nVSR1\n database contains 929 narrow (1 Hz, \nB=1/(2dt)\n) bands, covering the range \n100 - 1000 Hz. Neighboring bands overlap by 0.03125 Hz. \n\n\n\n\n4.1 O1 change of sampling \ndt\n (bandwidth \nB\n) and data length\n\n\nFor the \nO1\n data, the bandwidth was chosen to be \n0.25 Hz\n (\ndt\n was chosen to be equal \n2 s\n). Consequently, the reference band frequency \nfpo\n is defined as \n\n\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \n\n\n\nO1\n data thus contains \n{\\simeq} 2000\n narrow \n0.25 Hz\n bands in the frequency range \n10-500 Hz\n. Because of the sampling time change, the total number of data points in the 2 sideral day long segment is \nN=86164\n. For lower frequencies 6 day length segments are used. They contain \nN=258492\n double-precision numbers. \n\n\n5. Input data files\n\n\nA single run requires 2 data files for each detector \nDD\n, stored in \ndata_dir/nnn/DD\n \nsubdirectory, where \nDD\n is \nH1\n (Hanford), \nL1\n (Livingston), or \nV1\n (Virgo Cascina):\n\n\n\n\n\n\nxdat_nnn_bbb.bin\n - time-domain narrow-band data sequence, sampled\n     at  half second. \nnnn\n is the number of time frame, \nbbb\n is the\n     number of frequency band,\n\n\n\n\n\n\nDetSSB.bin\n  -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in\n     Cartesian coordinates, sampled at half second (3dim array of size \nN\n). \n     Last two records\n     of  this file  are the angle \nphir\n, determining the  position of\n     Earth in  its diurnal motion, and the obliquity of  the ecliptic\n     \nepsm\n, both calculated for the first sample of the data,\n\n\n\n\n\n\nas we as the sky positions-frequency-spindown grid file in linear coordinates \n(common for all the detectors), stored in \ndata_dir/nnn\n: \n\n\n\n\ngrid.bin\n - generator matrix of an optimal grid of templates. \n\n\n\n\n6. Output files\n\n\nBinary output  files,   containing  trigger  events   above  an  arbitrary\nthreshold, are written to  the output_dir directory.  There are two output\nfiles for every input data sequence: \ntriggers_nnn_bbb_1.bin\n and\n\ntriggers_nnn_bbb_2.bin\n,  where  \n1\n  and  \n2\n correspond to  northern  and\nsouthern  ecliptic  hemisphere. Every trigger (candidate) event  occupies \n40\n\nconsecutive bytes (5 double numbers), with the following meaning:\n\n\n\n\n\n\n\n\nRecord no.\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\nfrequency [radians, between 0 and \n\\pi\n] above \nfpo\n\n\n\n\n\n\n2\n\n\nspindown [Hz s\n-1\n]\n\n\n\n\n\n\n3\n\n\ndeclination [radians]\n\n\n\n\n\n\n4\n\n\nright ascension [radians]\n\n\n\n\n\n\n5\n\n\nsignal to noise ratio\n\n\n\n\n\n\n\n\n7. Auxiliary files\n\n\nThere is a couple of auxiliary files created by the \nsearch\n \nin the working directory:\n\n\n\n\n\n\nwisdom-hostname.dat\n - \"wisdom\" file created by the \nFFTW\n. The \nhostname\n \nvariable is determined by a call to \ngethostname()\n, \n\n\n\n\n\n\nstate_nnn_bbb.dat\n - checkpoint file.  The  search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.\n\n\n\n\n\n\n8. Versions\n\n\nPolgraw-allsky code comes also as an\n\nMPI\n,\n\nnetwork of detectors spotlight\nsearch\n and a\n\nGPU\n version.", 
            "title": "F-statistic candidate signal search"
        }, 
        {
            "location": "/search_for_candidates/#f-statistic-candidate-signal-search", 
            "text": "Production serial code for a network of detectors is available at  here .  OpenMP  version is at  this location . To get the whole pipeline, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "F-statistic candidate signal search"
        }, 
        {
            "location": "/search_for_candidates/#algorithm-flowchart", 
            "text": "", 
            "title": "Algorithm flowchart"
        }, 
        {
            "location": "/search_for_candidates/#1-prerequisites", 
            "text": "The code is written in standard  C .  GNU Scientific Library (GSL)  and the  FFTW library  (version 3.0 or later) are needed to run the code.  GNU struct dirent  objects are used to read the directories.   Optionally,  SLEEF  or  YEPPP! , libraries for high-performance computing that are optimized for speed are used to evaluate the trigonometric functions in the search code. These libraries are ported with the source code and are located in  src/lib . The choice which of these libraries to use has to be made at compilation time by modifying the  Makefile .", 
            "title": "1. Prerequisites"
        }, 
        {
            "location": "/search_for_candidates/#2-compilation-example-for-serial-cpu-code", 
            "text": "Run   make gwsearch-cpu  or  make  in  search/network/src-cpu  (default  C  version not-optimized with  openMP ; for the  openMP  version see the  search/network/src-openmp  directory). Resulting  binary is called  gwsearch-cpu . Modify the  Makefile  to fit your system. By default the  YEPPP!  library is selected.", 
            "title": "2. Compilation. Example for serial CPU code"
        }, 
        {
            "location": "/search_for_candidates/#3-how-to-run-the-program", 
            "text": "Minimal call to  gwsearch-cpu  is as follows (code compiled with the  GNUSINCOS  option):   ./gwsearch-cpu -data data_dir -dt 2 -output output_dir -ident frame -band band  where   data_dir  is the base directory of input data files,  Sampling time  dt  is 2 (seconds),   output_dir is a directory to write the output,  frame  is the number of time frame to be analyzed,  band  is the number of the frequency band (see the  data structure  description for details).", 
            "title": "3. How to run the program?"
        }, 
        {
            "location": "/search_for_candidates/#31-full-list-of-switches", 
            "text": "Switch  Description      -data  Data directory (default is  . )    -output  Output directory (default is  ./candidates )    -ident  Frame number    -band  Band number    -label  Custom label for the input and output files    -range  Use file with grid range or pulsar position    -getrange  Write grid ranges   save fft wisdom   exit (ignore -r)    -cwd  Change to directory  dir    -threshold  Threshold for the F-statistic (default is  20 )    -hemisphere  Hemisphere (default is 0 - does both)    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -usedet  Use only detectors from string (default is  use all available )    -addsig  Add signal with parameters from  file    -narrowdown  Narrow-down the frequency band (range  [0, 0.5] +- around center )     Also:            --whitenoise  White Gaussian noise assumed    --nospindown  Spindowns neglected    --nocheckpoint  State file will not be created (no checkpointing)    --help  This help", 
            "title": "3.1. Full list of switches"
        }, 
        {
            "location": "/search_for_candidates/#32-network-of-detectors", 
            "text": "For the examplary input data time streams  xdatc_001_0101.bin  provided in  test-data-network.tar.gz , the call is as follows:  LD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./gwsearch-cpu -data ./test-data-network -dt 2 -ident 001 -band 0101 -usedet H1V1 --nocheckpoint   where the  LD_LIBRARY_PATH  points to the location of the  YEPPP!  library.   The program will proceed assuming that the data directory  ./test-data-network/001  for the time frame  001  contain subdirectories for the network of detectors (here  H1  and  V1 ) with input time series  xdatc_001_0101.bin  and the ephemerids files  DetSSB.bin  in each subdirectory, with the sampling time  dt  equal 2 seconds. The grid of parameters files is expected to be in  ./test-data-network/001/grid.bin . Switch  -usedet H1  ( -usedet V1 ) select the appropriate data and performs single detector search. The  --nocheckpoint  disables the checkpointing (writing the last visited position on the grid to the  state  file).", 
            "title": "3.2. Network of detectors"
        }, 
        {
            "location": "/search_for_candidates/#33-network-of-detectors-in-spotlight-search-depreciated", 
            "text": "For the  H1L1  network of detectors, using the  test-data-network-injection.tar.gz  to search towards a pre-defined direction (spotlight search) in one 2-day segment:  LD_LIBRARY_PATH=lib/yeppp-1.0.0/binaries/linux/x86_64 ./search -data ./test-data-network-injection -ident 205 -band 000 -spotlight ./test-data-network-injection/205/spot_J0322+0441.dat -fpo 1391.3 -label J0322+0441 -dt 2    The injection corresponds to a pulsar J0322+0441. Note the differences with respect to the minimal call:    instead of calculating the band frequency  fpo  from  band , we provide it directly with the  -fpo  switch ( -band 000  is invoked for legacy),   the input data is denoted with the pulsar label, hence the  -label  switch,   the sampling time  dt  is now set to  2 s ,  -spotlight  switch points to the location of the spotlight file which contains the list of sky positions, and corresponding number and values of spindowns, in the following format:  \\begin{equation} \nh\\, N_{sky}\\, m_1\\, n_1\\, N^s_{1}\\, s_{1}\\, \\dots\\, s_{N^s_1}\\, \nm_2\\, n_2\\, N^s_{2}\\, s_1\\, \\dots\\, s_{N^s_2}\\, \\dots,  \n\\end{equation}  \nwhere  h  is the hemisphere number (1 or 2),  N_{sky}  is the total number of sky positions in a given spotlight search,  m_i  and  n_i  are the sky positions in linear (grid) coordinates,  N^s_{i}  is the number of spindowns, and  s_{i}\\,\\dots\\, s_{N^s_i}  and the spindowns (in linear coordinates), corresponding to the  i- th sky position.       Results are as follows:", 
            "title": "3.3. Network of detectors in spotlight search (depreciated)"
        }, 
        {
            "location": "/search_for_candidates/#34-one-detector-version", 
            "text": "In the case of  one-detector  version, test data is in  test-data.tar.gz . The directory  001  contains directly the  DetSSB.bin ,  grid.bin  and  xdatc_001_101.bin  files.", 
            "title": "3.4. One-detector version"
        }, 
        {
            "location": "/search_for_candidates/#4-data-structure", 
            "text": "We describe the structure using the VSR1 data as an example. \nTime of the first sample in MJD (Modified Julian Date) is 54239.00 \n(corresponding to 2007/05/18, UTC 12:00).   In this run the data was divided into 68 time frames, each of them 2 \nsideral  days  long, rounded to half second (172328 seconds each). \nSince we use the sampling time of  0.5s , total number of data points \nin each time frame is  N=344656 .   Frames are labelled with three-digit consecutive number, \nfrom  001  to  068 . Frame label is the name of a subfolder, containing \nall narrowband sequences corresponding to that frame, e.g.,  ./042 .  Beginning MJD of each time frame is saved in the  nnn/starting_date  \nfile:      % cat 042/starting_date \n    54320.7760185185   Reference band frequency  fpo  is defined for each band as   \nfpo = 100 + (1 - 2^{-5})\\cdot bbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}, \nwhere  bbb  is the band number, and  dt  is the data sampling time ( 0.5 s  for VSR1 data).  VSR1  database contains 929 narrow (1 Hz,  B=1/(2dt) ) bands, covering the range \n100 - 1000 Hz. Neighboring bands overlap by 0.03125 Hz.", 
            "title": "4. Data structure"
        }, 
        {
            "location": "/search_for_candidates/#41-o1-change-of-sampling-dt-bandwidth-b-and-data-length", 
            "text": "For the  O1  data, the bandwidth was chosen to be  0.25 Hz  ( dt  was chosen to be equal  2 s ). Consequently, the reference band frequency  fpo  is defined as  \nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}.   O1  data thus contains  {\\simeq} 2000  narrow  0.25 Hz  bands in the frequency range  10-500 Hz . Because of the sampling time change, the total number of data points in the 2 sideral day long segment is  N=86164 . For lower frequencies 6 day length segments are used. They contain  N=258492  double-precision numbers.", 
            "title": "4.1 O1 change of sampling dt (bandwidth B) and data length"
        }, 
        {
            "location": "/search_for_candidates/#5-input-data-files", 
            "text": "A single run requires 2 data files for each detector  DD , stored in  data_dir/nnn/DD  \nsubdirectory, where  DD  is  H1  (Hanford),  L1  (Livingston), or  V1  (Virgo Cascina):    xdat_nnn_bbb.bin  - time-domain narrow-band data sequence, sampled\n     at  half second.  nnn  is the number of time frame,  bbb  is the\n     number of frequency band,    DetSSB.bin   -  location  of  the  detector  w.r.t. the Solar\n   System Barycenter (SSB), in\n     Cartesian coordinates, sampled at half second (3dim array of size  N ). \n     Last two records\n     of  this file  are the angle  phir , determining the  position of\n     Earth in  its diurnal motion, and the obliquity of  the ecliptic\n      epsm , both calculated for the first sample of the data,    as we as the sky positions-frequency-spindown grid file in linear coordinates \n(common for all the detectors), stored in  data_dir/nnn :    grid.bin  - generator matrix of an optimal grid of templates.", 
            "title": "5. Input data files"
        }, 
        {
            "location": "/search_for_candidates/#6-output-files", 
            "text": "Binary output  files,   containing  trigger  events   above  an  arbitrary\nthreshold, are written to  the output_dir directory.  There are two output\nfiles for every input data sequence:  triggers_nnn_bbb_1.bin  and triggers_nnn_bbb_2.bin ,  where   1   and   2  correspond to  northern  and\nsouthern  ecliptic  hemisphere. Every trigger (candidate) event  occupies  40 \nconsecutive bytes (5 double numbers), with the following meaning:     Record no.       1  frequency [radians, between 0 and  \\pi ] above  fpo    2  spindown [Hz s -1 ]    3  declination [radians]    4  right ascension [radians]    5  signal to noise ratio", 
            "title": "6. Output files"
        }, 
        {
            "location": "/search_for_candidates/#7-auxiliary-files", 
            "text": "There is a couple of auxiliary files created by the  search  \nin the working directory:    wisdom-hostname.dat  - \"wisdom\" file created by the  FFTW . The  hostname  \nvariable is determined by a call to  gethostname() ,     state_nnn_bbb.dat  - checkpoint file.  The  search can  be safely restarted, calculations will continue  from the last grid position saved to this file. After successful termination, checkpoint file is left empty.", 
            "title": "7. Auxiliary files"
        }, 
        {
            "location": "/search_for_candidates/#8-versions", 
            "text": "Polgraw-allsky code comes also as an MPI , network of detectors spotlight\nsearch  and a GPU  version.", 
            "title": "8. Versions"
        }, 
        {
            "location": "/coincidences/", 
            "text": "Coincidences between candidates\n\n\nIn order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the \nF-statistic candidate signal search\n, the pipeline searches for coincidences between candidates found in different time frames. \n\n\nThe coincidences code is available at \ngithub\n. To get it, run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n.\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. The only dependency is \nGNU Scientific Library (GSL)\n, used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues). \nGNU struct dirent\n objects are used to read the directories. \n\n\nThe idea behind coincidences\n\n\nAfter finding the candidate signals in different time frames (\nsearch\n), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the \nfollowup\n, currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file\n\n\n\n\na candidate is transformed to a well-defined time moment (frequency shifted to a reference frame), \n\n\ntranslated into linear (integer) coordinates, \n\n\nduplicates within each frame are removed, \n\n\nlist of unique candidates from all the frames is created and sorted, \n\n\nduplicates are counted - these are the coincidences. \n\n\n\n\nTODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)\n \n\n\n7. Compilation\n\n\nRun \nmake coincidences\n; resulting binary is called \ncoincidences\n. Modify the \nMakefile\n to fit your system.\n\n\n8. How to run the program?\n\n\nSample call of \ncoincidences\n is as follows:\n\n\n ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2\n summary\n\n\n\n\n\nThis assumes that for the band \nbbbb=0666\n the band frequency \nfpo\n is 171.296875, because we define \n\n\nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}.\n\n\nThe reference grid file \ngrid.bin\n, corresponding to the reference frame \n010\n is located at the \n-refloc\n location. Some output is directed to \nstdin\n. The highest-coincidence is streamed to the \nsummary\n file via the \nstderr\n (\n2\n summary\n). \n\n\nIn principle one has to run the code 16 times for all the \n2^4\n shifts (all combinations of \n0000--1111\n).   \n\n\n8.1. Full list of switches\n\n\nType \n\n\n ./coincidences --help \n\n\n\n\n\nto obtain the following description: \n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-data\n\n\nData directory (default is \n./candidates\n)\n\n\n\n\n\n\n-output\n\n\nOutput directory (default is \n./coinc-results\n)\n\n\n\n\n\n\n-shift\n\n\nCell shifts in \nfsda\n directions (4 digit number, e.g. \n0101\n, default \n0000\n)\n\n\n\n\n\n\n-scale\n\n\nCell scaling in \nfsda\n directions (4 digit number, e.g. \n4824\n, default \n1111\n)\n\n\n\n\n\n\n-refr\n\n\nReference frame number\n\n\n\n\n\n\n-fpo\n\n\nReference band frequency \nfpo\n value\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: \n0.5\n)\n\n\n\n\n\n\n-trigname\n\n\nPart of triggers' name (for identifying files)\n\n\n\n\n\n\n-refloc\n\n\nLocation of the reference grid.bin and starting_date files\n\n\n\n\n\n\n-mincoin\n\n\nMinimal number of coincidences recorded\n\n\n\n\n\n\n-narrowdown\n\n\nNarrow-down the frequency band (range [0, 0.5] +- around center)\n\n\n\n\n\n\n-snrcutoff\n\n\nSignal-to-noise threshold cutoff (default value: 6)\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\n9. Output\n\n\nOutput to the screen (\nstdout\n) in the case of \n\n\n ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2\n summary\n\n\n\n\n\nis\n\n\nThe SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at 6d_xdat_0.25/010\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 2152.580016\nReference frame number: 10\nCell shifts  in f, s, d, a directions: 0 1 1 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers_005_0666_2.bin... Frame 5: 941/1879\nReading triggers_019_0666_2.bin... Frame 19: 1320/1794\nReading triggers_003_0666_2.bin... Frame 3: 1512/1920\nReading triggers_008_0666_2.bin... Frame 8: 3090/6849\nReading triggers_002_0666_2.bin... Frame 2: 1014/1173\nReading triggers_014_0666_2.bin... Frame 14: 779/1542\nReading triggers_006_0666_2.bin... Frame 6: 2884/8822\nReading triggers_011_0666_2.bin... Frame 11: 918/2896\nTotal number of candidates from all frames: 12458\n\n\n\n\n\nThe highest-coincidence is streamed to a \nsummary\n file via \nstderr\n:  \n\n\n cat summary \ntriggers_ 0110 171.296875 8 8 1.05795986e+00 -7.69412393e-09 -7.42581733e-01 5.39896106e+00 2.417267e+01 5 1879 941 19 1794 1320 3 1920 1512 8 6849 3090 2 1173 1014 14 1542 779 6 8822 2884 11 2896 918\n\n\n\n\n\nIt contains the \ntrigname\n identifier, the \nshift\n value, the \nfpo\n band frequency, the number of files read (8), and the highest coincidence found (8). Next 5 numbers are arithmetic mean values of the frequency \n\\,f\n (in radians), frequency derivative \n\\,\\dot{f}\n (spindown), sky positions \n\\delta\n and \n\\alpha\n, and the mean signal-to-noise ratio, \n\\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2}\n. The following integers are grouped in threes and denote the triggers/time frame number, number of all candidates in that triggers' file, and the number of unique candidates. \n\n\nCoincidences above \nmincoin\n are recorded in a binary file \n.coi\n, separately for each shift, in the \n-output\n directory. Each coincidence is a set of following numbers: \n\n\nN_{coin},\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{d},\\quad\\bar{a},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}\n\n\nwhere \n\n\n\n\n\n\nN_{coin}\n is the size of coincidence (written as one \nunsigned short int\n), \n\n\n\n\n\\bar{f}\n, \n\\bar{s}\n, \n\\bar{d}\n, \n\\bar{a}\n and \n\\widetilde{\\mathrm{snr}}\n are the mean parameters of the signal (\n5\\times\n\n\nfloat\n),\n\n\n\n\n\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}}\n are the frame numbers (\nN_{coin}\\times\n\n\nunsigned short int\n), \n\n\n\n\n\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}\n are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files (\nN_{coin}\\times\n\n\nint\n) \n\n\n\n\nin order to be able to recover the actual original candidate signals for further studies.", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#coincidences-between-candidates", 
            "text": "In order to establish the probability of detection of a real gravitational wave, after finding the candidate signals with the  F-statistic candidate signal search , the pipeline searches for coincidences between candidates found in different time frames.   The coincidences code is available at  github . To get it, run  git clone https://github.com/mbejger/polgraw-allsky.git .", 
            "title": "Coincidences between candidates"
        }, 
        {
            "location": "/coincidences/#prerequisites", 
            "text": "The code is written in standard  C . The only dependency is  GNU Scientific Library (GSL) , used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues).  GNU struct dirent  objects are used to read the directories.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/coincidences/#the-idea-behind-coincidences", 
            "text": "After finding the candidate signals in different time frames ( search ), we want to confirm the existence of signals with the same parameters along the span of time segments. to further perform a validation search for high-coincidence, or otherwise interesting candidates (the  followup , currently under construction). To do this, the candidates from a list of trigger files (time frames) are read, and for each trigger file   a candidate is transformed to a well-defined time moment (frequency shifted to a reference frame),   translated into linear (integer) coordinates,   duplicates within each frame are removed,   list of unique candidates from all the frames is created and sorted,   duplicates are counted - these are the coincidences.    TODO: describe cell shifts (16 different shifts in total: 0101, 0110, 0010 etc. in f, s, d, a directions) and scaling of cells (used to define the linear parameters for a given cell to subsequently compare the candidate values)", 
            "title": "The idea behind coincidences"
        }, 
        {
            "location": "/coincidences/#7-compilation", 
            "text": "Run  make coincidences ; resulting binary is called  coincidences . Modify the  Makefile  to fit your system.", 
            "title": "7. Compilation"
        }, 
        {
            "location": "/coincidences/#8-how-to-run-the-program", 
            "text": "Sample call of  coincidences  is as follows:   ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2  summary  This assumes that for the band  bbbb=0666  the band frequency  fpo  is 171.296875, because we define  \nfpo = 10 + (1 - 2^{-5})\\cdot bbbb\\cdot \\frac{1}{2dt}\\ \\mathrm{[Hz]}. \nThe reference grid file  grid.bin , corresponding to the reference frame  010  is located at the  -refloc  location. Some output is directed to  stdin . The highest-coincidence is streamed to the  summary  file via the  stderr  ( 2  summary ).   In principle one has to run the code 16 times for all the  2^4  shifts (all combinations of  0000--1111 ).", 
            "title": "8. How to run the program?"
        }, 
        {
            "location": "/coincidences/#81-full-list-of-switches", 
            "text": "Type    ./coincidences --help   to obtain the following description:      Switch  Description      -data  Data directory (default is  ./candidates )    -output  Output directory (default is  ./coinc-results )    -shift  Cell shifts in  fsda  directions (4 digit number, e.g.  0101 , default  0000 )    -scale  Cell scaling in  fsda  directions (4 digit number, e.g.  4824 , default  1111 )    -refr  Reference frame number    -fpo  Reference band frequency  fpo  value    -dt  Data sampling time dt (default value:  0.5 )    -trigname  Part of triggers' name (for identifying files)    -refloc  Location of the reference grid.bin and starting_date files    -mincoin  Minimal number of coincidences recorded    -narrowdown  Narrow-down the frequency band (range [0, 0.5] +- around center)    -snrcutoff  Signal-to-noise threshold cutoff (default value: 6)     Also:           --help  This help", 
            "title": "8.1. Full list of switches"
        }, 
        {
            "location": "/coincidences/#9-output", 
            "text": "Output to the screen ( stdout ) in the case of    ./coincidences -data . -output 0666-coincidences -mincoin 3 -snrcutoff 5 -trigname triggers_ -refloc 6d_xdat_0.25/010 -refr 010 -fpo 171.296875 -shift 0110 -scale 4444 -dt 2 2  summary  is  The SNR threshold cutoff is 5.000000000000, corresponding to F-statistic value of 14.500000000000\nReading the reference grid.bin at 6d_xdat_0.25/010\nfftpad from the grid file: 1\nSettings dt: 2.000000, oms: 2152.580016\nReference frame number: 10\nCell shifts  in f, s, d, a directions: 0 1 1 0 \nCell scaling in f, s, d, a directions: 4 4 4 4 \nReading triggers_005_0666_2.bin... Frame 5: 941/1879\nReading triggers_019_0666_2.bin... Frame 19: 1320/1794\nReading triggers_003_0666_2.bin... Frame 3: 1512/1920\nReading triggers_008_0666_2.bin... Frame 8: 3090/6849\nReading triggers_002_0666_2.bin... Frame 2: 1014/1173\nReading triggers_014_0666_2.bin... Frame 14: 779/1542\nReading triggers_006_0666_2.bin... Frame 6: 2884/8822\nReading triggers_011_0666_2.bin... Frame 11: 918/2896\nTotal number of candidates from all frames: 12458  The highest-coincidence is streamed to a  summary  file via  stderr :     cat summary \ntriggers_ 0110 171.296875 8 8 1.05795986e+00 -7.69412393e-09 -7.42581733e-01 5.39896106e+00 2.417267e+01 5 1879 941 19 1794 1320 3 1920 1512 8 6849 3090 2 1173 1014 14 1542 779 6 8822 2884 11 2896 918  It contains the  trigname  identifier, the  shift  value, the  fpo  band frequency, the number of files read (8), and the highest coincidence found (8). Next 5 numbers are arithmetic mean values of the frequency  \\,f  (in radians), frequency derivative  \\,\\dot{f}  (spindown), sky positions  \\delta  and  \\alpha , and the mean signal-to-noise ratio,  \\widetilde{\\mathrm{snr}}=\\sqrt{\\sum_i \\mathrm{snr}_i^2} . The following integers are grouped in threes and denote the triggers/time frame number, number of all candidates in that triggers' file, and the number of unique candidates.   Coincidences above  mincoin  are recorded in a binary file  .coi , separately for each shift, in the  -output  directory. Each coincidence is a set of following numbers:  \nN_{coin},\\quad\\bar{f},\\quad\\bar{s},\\quad\\bar{d},\\quad\\bar{a},\\quad\\widetilde{\\mathrm{snr}},\\quad\\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}},\\quad\\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}} \nwhere     N_{coin}  is the size of coincidence (written as one  unsigned short int ),    \\bar{f} ,  \\bar{s} ,  \\bar{d} ,  \\bar{a}  and  \\widetilde{\\mathrm{snr}}  are the mean parameters of the signal ( 5\\times  float ),   \\mathrm{fr}_{1},\\,\\dots\\,\\mathrm{fr}_{N_{coin}}  are the frame numbers ( N_{coin}\\times  unsigned short int ),    \\mathrm{p}_{1},\\,\\dots\\,\\mathrm{p}_{N_{coin}}  are the positions of candidate signals that took part in the coincidences, in their corresponding trigger files ( N_{coin}\\times  int )    in order to be able to recover the actual original candidate signals for further studies.", 
            "title": "9. Output"
        }, 
        {
            "location": "/fap_coincidences/", 
            "text": "False alarm probability of coincidences\n\n\nA general formula for probability that is used in the estimation of significance of the coincidences is implemented. The code is available at \ngithub\n. Run \ngit clone https://github.com/mbejger/polgraw-allsky.git\n to get the repository.\n\n\nPrerequisites\n\n\nThe code is written in standard \nC\n. The only dependency is \nGNU Scientific Library (GSL)\n, used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues), the \n\\Gamma\n function and for the combinations. \n\n\nTheoretical description\n\n\nThis description is a short Appendix version of \nImplementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data\n. \n\n\nFor a given frequency band we analyze \nL\n non-overlapping time segments: the search in the \nl\nth segment produces \nN_l\n candidates. The size of the parameter space for each time segment is the same and it can be divided into the number \nN_{\\rm cell}\n of independent cells. The code tests the null hypothesis that the coincidences among candidates from \nL\n segments are accidental.\nThe probability for a candidate event to fall into any given coincidence cell is equal to \n1/N_{\\rm cell}\n. The probability \n\\epsilon_l\n that a given coincidence cell is populated with one or more candidate events is given by\n\n\n\\epsilon_l = 1 - \\Big(1 - \\frac{1}{N_{\\rm cell}}\\Big)^{N_l},  \n\\quad\\text{and for independent candidates (one candidate in one cell) it is}\\quad  \n\\epsilon_l = \\frac{N_l}{N_{\\rm cell}}. \n\n\nFor two or more candidates within a given cell we choose the one with the highest signal-to-noise ratio. The probability \np_F(N_{\\rm cell})\n that any given coincidence cell out of the total of \nN_{\\rm cell}\n cells contains candidate events from \nC_{max}\n or more distinct data segments is given by a generalized binomial distribution: \n\n\\begin{eqnarray}\np_F(N_{\\rm cell}) &=& \\sum_{n=C_{max}}^{L} \\frac{1}{n!(L-n)!} \\times \\sum_{\\sigma\\in\\Pi(L)} \\epsilon_{\\sigma(1)}\\ldots\\epsilon_{\\sigma(n)}(1-\\epsilon_{\\sigma(n+1)})\\ldots(1-\\epsilon_{\\sigma(L)}),\n\\end{eqnarray}\n\nwhere \n\\sum_{\\sigma \\in \\Pi(L)}\n is the sum over all permutations of \nL\n data sequences.\nFinally the probability \nP_F\n that there is \n{\\mathcal C}_{max}\n or more coincidences\nin one or more of the \nN_{\\rm cell}\n cells is\n\n\\begin{equation}\nP_F = 1 - \\left(1 - p_F(N_{\\rm cell})\\right)^{N_{\\rm cell}}.\n\\end{equation}\n\n\n\n\nIn order to find coincidences the entire cell coincidence grid is shifted by half a cell width in all possible \n2^4 = 16\n combinations of the four parameter-space dimensions of \n(f, \\dot{f}, \\delta, \\alpha)\n, and coincidences are searched in all the 16 coincidence grids. It does not account for cases when candidate events are located on opposite sides of cell borders, edges, and corners. This leads to a higher number of accidental coincidences, and consequently it underestimates the false alarm probability.\n\n\nIn the four dimension parameter space of \n(f, \\dot{f}, \\delta, \\alpha)\n the formula for the probability \nP^{\\rm shifts}_F\n that there are \n{\\mathcal C}_{\\mathrm{max}}\n or more independent coincidences in one or more of the \nN_{\\rm cell}\n cells in all 16 grid shifts is \n\n\\begin{eqnarray}\n\\label{eq:FAPs}\nP^{\\rm shifts}_F = 1 - \\bigg[ 1 - \\Big( 2^4 p_F(N_c) \n- \\Big( {4 \\choose 1} p_F(2 N_c) + {4 \\choose 2} p_F(2^2 N_c) \n+ {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c)   \\Big) \\\\ \\nonumber  \n- \\Big({4 \\choose 2} p_F(2^2 N_c) + {4 \\choose 3} p_F(2^3 N_c) \n+ {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- \\Big( {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- {4 \\choose 4} p_F(2^4 N_c)\\Big)  \\bigg]^{N_c}.\n\\end{eqnarray}\n\n\n\n\nBy choosing a certain false alarm probability \nP_F\n, we can calculate the threshold number \n{\\mathcal C}_{\\mathrm{max}}\n of coincidences. If we obtain more than \n{\\mathcal C}_{\\mathrm{max}}\n coincidences, the null hypothesis that coincidences are accidental is rejected at the significance level of \nP_F\n.\n\n\nCompilation\n\n\nRun \nmake fap\n; resulting binary is called \nfap\n (modify the \nMakefile\n to fit your system).\n\n\nHow to run the program?\n\n\nSample call of \nfap\n is\n\n\n ./fap -nod 6 -band 0600 -data test-fap/summary_0600_1.txt -grid test-fap/ -vetofrac 0.222837 -cellsize 4 -threshold 0.2 \n\n\n\n\n\nNumber of days in the time segment \nnod\n equals 6, fraction of the band vetoed \nvetofrac\n is 0.222837 and the cell size \ncellsize\n is 4. Directory containing the grid matrix file \ngrid.bin\n should be pointed out by the \ngrid\n switch. The input data file \ntest-fap/summary_0600_1.txt\n is a line from the \ncoincidences\n output: \n\n\n0600_1 1110 155.312500     8     5  1.46199508e+00 1.30224869e-09 1.09355692e+00 2.08138626e+00 1.198182e+01 3 2020252 1969390 6 2137490 2038513 14 1752761 1666583 8 5526511 3334399 5 1827438 1790517\n\n\n\n\n\nFull list of switches\n\n\nType \n\n\n ./fap --help \n\n\n\n\n\nto obtain the following description: \n\n\n\n\n\n\n\n\nSwitch\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-band\n\n\nBand number\n\n\n\n\n\n\n-cellsize\n\n\nCell size (default value: 4)\n\n\n\n\n\n\n-data\n\n\nCoincidence summary file\n\n\n\n\n\n\n-grid\n\n\nGrid matrix directory (default value: .)\n\n\n\n\n\n\n-dt\n\n\nData sampling time dt (default value: 2)\n\n\n\n\n\n\n-threshold\n\n\nFAP threshold (default value: 0.1)\n\n\n\n\n\n\n-nod\n\n\nNumber of days\n\n\n\n\n\n\n-vetofrac\n\n\nVetoed fraction of the band (default value: 0)\n\n\n\n\n\n\n\n\nAlso:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n--help\n\n\nThis help\n\n\n\n\n\n\n\n\nOutput\n\n\nOutput to the screen (\nstdout\n) in the case of \n\n\n ./fap -nod 6 -band 0600 -data test-fap/summary_0600_1.txt -grid test-fap/ -vetofrac 0.222837 -cellsize 4 -threshold 0.2 \n\n\n\n\n\nis\n\n\nNumber of days in time segments: 6\nInput data: test-fap/summary_0600_1.txt\nGrid matrix data directory: test-fap/\nBand number: 0600 (veto fraction: 0.222837)\nThe reference frequency fpo: 155.312500\nThe data sampling time dt: 2.000000\nFAP threshold: 0.200000\nCell size: 4\n\n\n\n\n\nwhereas the result (if \nthreshold\n is reached) is printed to \nstderr\n: \n\n\n#band f_min        f_max        PFshifts      noc Nkall    f s d a hemisphere \n0600  1.553125e+02 1.555625e+02 1.810747e-01  5   10799402 1.461995e+00 1.302249e-09 1.093557e+00 2.081386e+00 1.198182e+01 1", 
            "title": "False alarm probablity of conicidences"
        }, 
        {
            "location": "/fap_coincidences/#false-alarm-probability-of-coincidences", 
            "text": "A general formula for probability that is used in the estimation of significance of the coincidences is implemented. The code is available at  github . Run  git clone https://github.com/mbejger/polgraw-allsky.git  to get the repository.", 
            "title": "False alarm probability of coincidences"
        }, 
        {
            "location": "/fap_coincidences/#prerequisites", 
            "text": "The code is written in standard  C . The only dependency is  GNU Scientific Library (GSL) , used to manipulate the Fisher matrix (calculate the eigenvectors and eigenvalues), the  \\Gamma  function and for the combinations.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/fap_coincidences/#theoretical-description", 
            "text": "This description is a short Appendix version of  Implementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data .   For a given frequency band we analyze  L  non-overlapping time segments: the search in the  l th segment produces  N_l  candidates. The size of the parameter space for each time segment is the same and it can be divided into the number  N_{\\rm cell}  of independent cells. The code tests the null hypothesis that the coincidences among candidates from  L  segments are accidental.\nThe probability for a candidate event to fall into any given coincidence cell is equal to  1/N_{\\rm cell} . The probability  \\epsilon_l  that a given coincidence cell is populated with one or more candidate events is given by \n\\epsilon_l = 1 - \\Big(1 - \\frac{1}{N_{\\rm cell}}\\Big)^{N_l},  \n\\quad\\text{and for independent candidates (one candidate in one cell) it is}\\quad  \n\\epsilon_l = \\frac{N_l}{N_{\\rm cell}}.  \nFor two or more candidates within a given cell we choose the one with the highest signal-to-noise ratio. The probability  p_F(N_{\\rm cell})  that any given coincidence cell out of the total of  N_{\\rm cell}  cells contains candidate events from  C_{max}  or more distinct data segments is given by a generalized binomial distribution:  \\begin{eqnarray}\np_F(N_{\\rm cell}) &=& \\sum_{n=C_{max}}^{L} \\frac{1}{n!(L-n)!} \\times \\sum_{\\sigma\\in\\Pi(L)} \\epsilon_{\\sigma(1)}\\ldots\\epsilon_{\\sigma(n)}(1-\\epsilon_{\\sigma(n+1)})\\ldots(1-\\epsilon_{\\sigma(L)}),\n\\end{eqnarray} \nwhere  \\sum_{\\sigma \\in \\Pi(L)}  is the sum over all permutations of  L  data sequences.\nFinally the probability  P_F  that there is  {\\mathcal C}_{max}  or more coincidences\nin one or more of the  N_{\\rm cell}  cells is \\begin{equation}\nP_F = 1 - \\left(1 - p_F(N_{\\rm cell})\\right)^{N_{\\rm cell}}.\n\\end{equation}   In order to find coincidences the entire cell coincidence grid is shifted by half a cell width in all possible  2^4 = 16  combinations of the four parameter-space dimensions of  (f, \\dot{f}, \\delta, \\alpha) , and coincidences are searched in all the 16 coincidence grids. It does not account for cases when candidate events are located on opposite sides of cell borders, edges, and corners. This leads to a higher number of accidental coincidences, and consequently it underestimates the false alarm probability.  In the four dimension parameter space of  (f, \\dot{f}, \\delta, \\alpha)  the formula for the probability  P^{\\rm shifts}_F  that there are  {\\mathcal C}_{\\mathrm{max}}  or more independent coincidences in one or more of the  N_{\\rm cell}  cells in all 16 grid shifts is  \\begin{eqnarray}\n\\label{eq:FAPs}\nP^{\\rm shifts}_F = 1 - \\bigg[ 1 - \\Big( 2^4 p_F(N_c) \n- \\Big( {4 \\choose 1} p_F(2 N_c) + {4 \\choose 2} p_F(2^2 N_c) \n+ {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c)   \\Big) \\\\ \\nonumber  \n- \\Big({4 \\choose 2} p_F(2^2 N_c) + {4 \\choose 3} p_F(2^3 N_c) \n+ {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- \\Big( {4 \\choose 3} p_F(2^3 N_c) + {4 \\choose 4} p_F(2^4 N_c) \\Big) \n- {4 \\choose 4} p_F(2^4 N_c)\\Big)  \\bigg]^{N_c}.\n\\end{eqnarray}   By choosing a certain false alarm probability  P_F , we can calculate the threshold number  {\\mathcal C}_{\\mathrm{max}}  of coincidences. If we obtain more than  {\\mathcal C}_{\\mathrm{max}}  coincidences, the null hypothesis that coincidences are accidental is rejected at the significance level of  P_F .", 
            "title": "Theoretical description"
        }, 
        {
            "location": "/fap_coincidences/#compilation", 
            "text": "Run  make fap ; resulting binary is called  fap  (modify the  Makefile  to fit your system).", 
            "title": "Compilation"
        }, 
        {
            "location": "/fap_coincidences/#how-to-run-the-program", 
            "text": "Sample call of  fap  is   ./fap -nod 6 -band 0600 -data test-fap/summary_0600_1.txt -grid test-fap/ -vetofrac 0.222837 -cellsize 4 -threshold 0.2   Number of days in the time segment  nod  equals 6, fraction of the band vetoed  vetofrac  is 0.222837 and the cell size  cellsize  is 4. Directory containing the grid matrix file  grid.bin  should be pointed out by the  grid  switch. The input data file  test-fap/summary_0600_1.txt  is a line from the  coincidences  output:   0600_1 1110 155.312500     8     5  1.46199508e+00 1.30224869e-09 1.09355692e+00 2.08138626e+00 1.198182e+01 3 2020252 1969390 6 2137490 2038513 14 1752761 1666583 8 5526511 3334399 5 1827438 1790517", 
            "title": "How to run the program?"
        }, 
        {
            "location": "/fap_coincidences/#full-list-of-switches", 
            "text": "Type    ./fap --help   to obtain the following description:      Switch  Description      -band  Band number    -cellsize  Cell size (default value: 4)    -data  Coincidence summary file    -grid  Grid matrix directory (default value: .)    -dt  Data sampling time dt (default value: 2)    -threshold  FAP threshold (default value: 0.1)    -nod  Number of days    -vetofrac  Vetoed fraction of the band (default value: 0)     Also:           --help  This help", 
            "title": "Full list of switches"
        }, 
        {
            "location": "/fap_coincidences/#output", 
            "text": "Output to the screen ( stdout ) in the case of    ./fap -nod 6 -band 0600 -data test-fap/summary_0600_1.txt -grid test-fap/ -vetofrac 0.222837 -cellsize 4 -threshold 0.2   is  Number of days in time segments: 6\nInput data: test-fap/summary_0600_1.txt\nGrid matrix data directory: test-fap/\nBand number: 0600 (veto fraction: 0.222837)\nThe reference frequency fpo: 155.312500\nThe data sampling time dt: 2.000000\nFAP threshold: 0.200000\nCell size: 4  whereas the result (if  threshold  is reached) is printed to  stderr :   #band f_min        f_max        PFshifts      noc Nkall    f s d a hemisphere \n0600  1.553125e+02 1.555625e+02 1.810747e-01  5   10799402 1.461995e+00 1.302249e-09 1.093557e+00 2.081386e+00 1.198182e+01 1", 
            "title": "Output"
        }, 
        {
            "location": "/pipeline_script/", 
            "text": "Pipeline: a minimal example\n\n\n1. Sample PBS/Torque script\n\n\nThis is a sample \npipeline.sh\n script for the spotlight version of the \nsearch\n code, designed to look for signal around a specific location given by the spotlight range data file for 2-day narrow-band data segments. After the candidate signals are found, the search for coincidences is performed. It is currently used in the Mock Data Challenge with injected signals.  \n\n\nThis script uses a lower threshold (option \n-t 10\n) while searching for candidate signals, looks for coincidences in a \n[4 4 4 4]\n cell (see options to \ncoiproc\n) and prepares the summary of the estimation (\nsummary\n file) at the end of execution. The binary files \n*.coi\n - results of coincidences - are archived with the \nlz4.gz\n (\nlz4\n) compression to save space, and deleted after the coincidences procedure is done.  \n\n\n#!/bin/bash \n\n\n#PBS -m n \n\n\n#PBS -j oe\n\n\n#PBS -q medium\n\n\n#PBS -l walltime=48:00:00\n\n\n\n# Data directory \n\n\ndata\n=\n/work/psk/bejger/mdc/pulsar-data\n\n# Candidate (triggers) files output directory \n\n\ncandout\n=\n/work/psk/bejger/mdc/cand-mdcthr10_\n$FILENUM\n\n\n\n# Directory with coincidence codes \n\n\ncoisrc\n=\n/work/psk/bejger/mdc/coincidences-codes-binary\n\n# Coincidences output directory \n\n\ncoiout\n=\n/work/psk/bejger/mdc/coin-mdcthr10_\n$FILENUM\n\n\n\n# Path to the libraries (in the src/lib directory of the search code)\n\n\nldlp\n=\n/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n\n# Path to lz4 compressor\n\n\nlz4path\n=\n/work/psk/bejger/codes/lz4-r131/programs\n\n\ncd\n \n$PBS_O_WORKDIR\n\n\n\nwhile\n \nread\n line\n;\n \ndo\n\n\n  \n# pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n\n  \n# the master file is mdc_1561pulsars (name fpo f_gw) \n\n  \nname\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $1}\n)\n\n  \nfgw\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $3}\n)\n\n  \nfpo\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $2}\n)\n\n\n  \n#-----------------------\n\n  \n# Search for candidates \n\n  \n#-----------------------\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncandidate search\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n  \n# search in frames xxx -- yyy  \n\n  \nfor\n i in \n$(\nseq -f %03g \n1\n 210\n)\n;\n \ndo\n\n\n    \n# spotlight file range location \n\n    \nspoth1\n=\n${\ndata\n}\n/\n${\ni\n}\n/H1/spot_\n${\nname\n}\n.dat\n    \nspotl1\n=\n${\ndata\n}\n/\n${\ni\n}\n/L1/spot_\n${\nname\n}\n.dat\n\n    \n# Here we assume that both H1 and L1 data is present for segment $i, \n\n    \n# and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n\n    \n# it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n\n    \n# If both $spoth1 and $spotl1 are missing, it means there is no good data \n\n    \n# and the code exits (since there is nothing to analyze).\n\n\n    \nspotfile\n=\n\n    \nif\n \n[\n -f \n$spoth1\n \n]\n;\n \nthen\n \nspotfile\n=\n$spoth1\n \n    \nelse\n \nspotfile\n=\n$spotl1\n\n    \nfi\n \n\n    \n# threshold is set to -threshold 10\n\n    \nLD_LIBRARY_PATH\n=\n$ldlp\n ./search -data \n$data\n -ident \n$i\n -band \n000\n --nocheckpoint -output \n$candout\n -spotlight \n$spotfile\n -fpo \n$fpo\n -label \n$name\n -dt \n2\n -threshold \n10\n 1\n \n$name\n.\n$PBS_JOBID\n.out 2\n \n$name\n.\n$PBS_JOBID\n.err\n\n  \ndone\n \n\n  \n#------------------------------------------ \n\n  \n# Search for coincidences among candidates \n\n  \n#------------------------------------------\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncoincidences\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n\n  mkdir -p \n$coiout\n/\n$name\n;\n \ncd\n \n$coiout\n/\n$name\n\n\n  \n# Copying the trigger files to the working directory \n\n  cp \n$candout\n/triggers*\n${\nname\n}\n*.bin .\n\n  \n# Name for the list of files \n\n  \nst\n=\n$(\nls triggers*\n${\nname\n}\n*.bin \n|\n tail -1\n)\n;\n \nlistfile\n=\n${\nst\n: -16:\n10\n}\n_000\n${\nst\n: -6:\n2\n}\n.list\n;\n\n  \necho\n \nName for the list of files: \n \n$listfile\n \n\n  \necho\n \nRemoving the name of the pulsar from the triggers\n files...\n\n  \nfor\n f in \n$(\nls triggers_*.bin\n)\n;\n \ndo\n mv \n$f\n \n${\nf\n:\n0\n:\n16\n}${\nf\n: -6:\n6\n}\n;\n \ndone\n\n\n  \necho\n \nVetoing: processing the triggers\n files...\n \n  \nfor\n f in \n$(\nls triggers_*.bin\n)\n;\n \ndo\n \n    \n$coisrc\n/trigveto -noveto -fpo \n$fpo\n \n$f\n  \n    \n# Removing original triggers files \n\n    rm \n$f\n \n  \ndone\n \n\n  \necho\n \nRemoving candidates outside a narrow frequency band (+- 0.05)...\n\n  \nfor\n f in \n$(\nls pvc_*.bin\n)\n;\n \ndo\n\n    \n$coisrc\n/decym \n$f\n \n$fgw\n 0.05\n  \ndone\n\n\n  \necho\n \nWriting list of pvc files to \n \n$listfile\n \n  ls pvc_*.bin \n \n$listfile\n\n\n  \necho\n \nSearching for coincidences...\n \n  \nfor\n i in \n{\n0..1\n}{\n0..1\n}{\n0..1\n}{\n0..1\n}\n;\n \ndo\n \n    \n$coisrc\n/coiproc -binary -refr \n100\n -scale_f \n4\n -scale_s \n4\n -scale_a \n4\n -scale_d \n4\n -shift \n$i\n -fpo \n$fpo\n \n$listfile\n \n  \ndone\n\n\n  \necho\n \nGenerating the stat file...\n \n  \nst\n=\n$(\ngrep \nMax value\n *.resf \n|\n sort -gk \n5\n \n|\n tail -1\n)\n\n  \nmcoi\n=\n$(\necho\n \n$st\n \n|\n awk \n{print $5}\n)\n\n  \nresf\n=\n$(\necho\n \n$st\n \n|\n awk \n{print $1}\n)\n\n  \nresf\n=\n${\nresf\n:\n0\n:\n10\n}\n \n  \n$coisrc\n/resf2stat -threshold \n$mcoi\n -binary \n$resf\n \n\n  \necho\n \nEstimating the parameters...\n\n  \n$coisrc\n/stat2data -threshold \n$mcoi\n -refr \n100\n . *.stat\n\n  \necho\n \nPreparing the summary...\n \n  \nst\n=\n$(\nfind . -name \n*.stat.dat\n -printf \n%f\\n\n)\n\n  \nif\n \n[\n -z \n$st\n \n]\n;\n \nthen\n\n    \necho\n \n$name\n \n$fpo\n \nno coincidences\n \n ../summary\n  \nelse\n\n    \necho\n \n$name\n \n$fpo\n \n$(\nwc -l \n \n$listfile\n)\n \n$(\nawk \nEND{printf \n%20s %.9e %.9e %.9e %.9e %.9e\n,FILENAME,$3,$4,$5,$6,$7}\n \n$st\n)\n \n ../summary\n  \nfi\n \n\n  \n# Cleanup (archiving and deleting the coi files) \n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \narchiving coi files\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n  \nfor\n r in \n$(\nls *.coi\n)\n;\n \ndo\n \n    \n${\nlz4path\n}\n/lz4 -6 \n${\nr\n}\n \n${\nr\n}\n.lz4 \n gzip \n${\nr\n}\n.lz4\n    \nif\n \n[\n -f \n${\nr\n}\n.lz4.gz\n \n]\n;\n \nthen\n \n      rm \n$r\n\n    \nfi\n \n  \ndone\n \n\n  \ncd\n \n$PBS_O_WORKDIR\n\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \nend\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n\ndone\n \n pulsar_file_\n$FILENUM\n\n\n\nexit\n 0\n\n\n\n\n\nwhere the \npulsar_file_$FILENUM\n contains 3 columns: pulsar \nname\n, \nfpo\n reference frequency and gravitational wave frequency of the pulsar \nfgw\n. For an exemplary \npulsar_file_666\n, contaning 8 pulsars,  \n\n\nJ0440+6416 516.601562 516.721000\nJ0714-6355 538.630859 538.755400\nJ0424+3800 561.185547 561.302200\nJ0303-5616 1089.595703 1089.719400\nJ0612+3324 390.177734 390.297600\nJ0319-7629 466.138672 466.263800\nJ0803-6214 1700.154297 1700.281800\nJ0534+0935 258.660156 258.781000\n\n\n\n\n\nthe job can be sent to the PBS queue in the following way:  \n\n\nqsub -v FILENUM=666 -N mdc-666 pipeline.sh\n\n\n\n\n\n2. Sample PBS/Torque script using the \nC\n coincidences code\n\n\n#!/bin/bash \n\n\n#PBS -m n \n\n\n#PBS -j oe\n\n\n#PBS -q medium\n\n\n#PBS -l mem=2GB\n\n\n#PBS -l walltime=04:00:00\n\n\n\n# Data directory \n\n\ndata\n=\n/work/psk/bejger/mdc/pulsar-data\n\n# Candidate (triggers) files output directory \n\n\ncandout\n=\n/work/psk/bejger/mdc/candidates-mdc-thr10\n\n\n# Directory with coincidence codes \n\n\ncoisrc\n=\n/work/psk/bejger/mdc/ccoin\n\n# Coincidences output directory \n\n\ncoiout\n=\n/work/psk/bejger/mdc/coin-mdcthr10\n\n\n# Path to the libraries (in the src/lib directory of the search code)\n\n\nldlp\n=\n/work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64\n\n\n# Path to lz4 compressor\n\n\nlz4path\n=\n/work/psk/bejger/codes/lz4-r131/programs\n\n\ncd\n \n$PBS_O_WORKDIR\n\n\n\nwhile\n \nread\n line\n;\n \ndo\n\n\n  \n# pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM)\n\n  \n# the master file is mdc_1561pulsars (name fpo f_gw) \n\n  \nname\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $1}\n)\n\n  \nfgw\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $3}\n)\n\n  \nfpo\n=\n$(\necho\n \n$line\n \n|\n awk \n{print $2}\n)\n\n\n  \n#-----------------------\n\n  \n# Search for candidates \n\n  \n#-----------------------\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncandidate search\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n  \n# search in frames xxx -- yyy  \n\n  \nfor\n i in \n$(\nseq -f %03g \n1\n 210\n)\n;\n \ndo\n\n\n    \n# spotlight file range location \n\n    \nspoth1\n=\n${\ndata\n}\n/\n${\ni\n}\n/H1/spot_\n${\nname\n}\n.dat\n    \nspotl1\n=\n${\ndata\n}\n/\n${\ni\n}\n/L1/spot_\n${\nname\n}\n.dat\n\n    \n# Here we assume that both H1 and L1 data is present for segment $i, \n\n    \n# and take the H1 spotlight file to analyze it. If $spoth1 is not present, \n\n    \n# it means there is no good H1 data. We then try $spotl1 as the spotlight file.  \n\n    \n# If both $spoth1 and $spotl1 are missing, it means there is no good data \n\n    \n# and the code exits (since there is nothing to analyze).\n\n\n    \nspotfile\n=\n\n    \nif\n \n[\n -f \n$spoth1\n \n]\n;\n \nthen\n \nspotfile\n=\n$spoth1\n \n    \nelse\n \nspotfile\n=\n$spotl1\n\n    \nfi\n \n\n    \n# threshold is set to -threshold 10\n\n    \nLD_LIBRARY_PATH\n=\n$ldlp\n ./search -data \n$data\n -ident \n$i\n -band \n000\n --nocheckpoint -output \n$candout\n -spotlight \n$spotfile\n -fpo \n$fpo\n -label \n$name\n -dt \n2\n -threshold \n10\n 1\n \n$name\n.\n$PBS_JOBID\n.out 2\n \n$name\n.\n$PBS_JOBID\n.err\n\n  \ndone\n \n\n  \n#------------------------------------------ \n\n  \n# Search for coincidences among candidates \n\n  \n#------------------------------------------\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncoinc: start\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n  \n# Creating a directory for each pulsar coincidence files \n\n  mkdir -p \n$coiout\n/\n$name\n\n\n  \n# Searching for coincidences \n\n  \nfor\n shi in \n{\n0..1\n}{\n0..1\n}{\n0..1\n}{\n0..1\n}\n;\n \ndo\n\n    ./coincidences -data \n$candout\n -trigname \n$name\n -refloc \n${\ncoisrc\n}\n/coinc-testdata -fpo \n$fpo\n -shift \n$shi\n -scale \n4444\n -refr \n100\n -dt \n2\n -mincoin \n15\n -narrowdown 0.2 -output \n${\ncoiout\n}\n/\n${\nname\n}\n 2\n \n${\ncoiout\n}\n/\n${\nname\n}\n/summary 1\n /dev/null  \n  \ndone\n\n\n  \n# Selecting maximal coincidence among all 16 shifts (col. 5) \n\n  \n# If many, select the one with highest SNR (col. 10)  \n\n  sort -rgk5 -gk10 \n${\ncoiout\n}\n/\n${\nname\n}\n/summary \n|\n head -1 \n \n${\ncoiout\n}\n/summary \n\n  \n#------------------------------------------ \n\n  \n# Cleanup \n\n  \n#------------------------------------------\n\n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncoinc: archiving coi files\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n  \nfor\n r in \n$(\nls \n${\ncoiout\n}\n/\n${\nname\n}\n/*.coi\n)\n;\n \ndo\n \n    \n${\nlz4path\n}\n/lz4 -6 \n${\nr\n}\n \n${\nr\n}\n.lz4 \n gzip \n${\nr\n}\n.lz4\n    \nif\n \n[\n -f \n${\nr\n}\n.lz4.gz\n \n]\n;\n \nthen\n \n      rm \n$r\n\n    \nfi\n \n  \ndone\n \n\n  \necho\n \n$name\n \n$(\ndate +%H:%M:%S\n)\n \ncoinc: end\n \n \n$PBS_O_WORKDIR\n/timing_\n$FILENUM\n\n\n\ndone\n \n pulsar_file_\n$FILENUM\n\n\n\nexit\n 0", 
            "title": "Pipeline: a minimal example"
        }, 
        {
            "location": "/pipeline_script/#pipeline-a-minimal-example", 
            "text": "", 
            "title": "Pipeline: a minimal example"
        }, 
        {
            "location": "/pipeline_script/#1-sample-pbstorque-script", 
            "text": "This is a sample  pipeline.sh  script for the spotlight version of the  search  code, designed to look for signal around a specific location given by the spotlight range data file for 2-day narrow-band data segments. After the candidate signals are found, the search for coincidences is performed. It is currently used in the Mock Data Challenge with injected signals.    This script uses a lower threshold (option  -t 10 ) while searching for candidate signals, looks for coincidences in a  [4 4 4 4]  cell (see options to  coiproc ) and prepares the summary of the estimation ( summary  file) at the end of execution. The binary files  *.coi  - results of coincidences - are archived with the  lz4.gz  ( lz4 ) compression to save space, and deleted after the coincidences procedure is done.    #!/bin/bash   #PBS -m n   #PBS -j oe  #PBS -q medium  #PBS -l walltime=48:00:00  # Data directory   data = /work/psk/bejger/mdc/pulsar-data # Candidate (triggers) files output directory   candout = /work/psk/bejger/mdc/cand-mdcthr10_ $FILENUM  # Directory with coincidence codes   coisrc = /work/psk/bejger/mdc/coincidences-codes-binary # Coincidences output directory   coiout = /work/psk/bejger/mdc/coin-mdcthr10_ $FILENUM  # Path to the libraries (in the src/lib directory of the search code)  ldlp = /work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64 # Path to lz4 compressor  lz4path = /work/psk/bejger/codes/lz4-r131/programs cd   $PBS_O_WORKDIR  while   read  line ;   do \n\n   # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM) \n   # the master file is mdc_1561pulsars (name fpo f_gw)  \n   name = $( echo   $line   |  awk  {print $1} ) \n   fgw = $( echo   $line   |  awk  {print $3} ) \n   fpo = $( echo   $line   |  awk  {print $2} ) \n\n   #----------------------- \n   # Search for candidates  \n   #----------------------- \n   echo   $name   $( date +%H:%M:%S )   candidate search     $PBS_O_WORKDIR /timing_ $FILENUM \n\n   # search in frames xxx -- yyy   \n   for  i in  $( seq -f %03g  1  210 ) ;   do \n\n     # spotlight file range location  \n     spoth1 = ${ data } / ${ i } /H1/spot_ ${ name } .dat\n     spotl1 = ${ data } / ${ i } /L1/spot_ ${ name } .dat\n\n     # Here we assume that both H1 and L1 data is present for segment $i,  \n     # and take the H1 spotlight file to analyze it. If $spoth1 is not present,  \n     # it means there is no good H1 data. We then try $spotl1 as the spotlight file.   \n     # If both $spoth1 and $spotl1 are missing, it means there is no good data  \n     # and the code exits (since there is nothing to analyze). \n\n     spotfile = \n     if   [  -f  $spoth1   ] ;   then   spotfile = $spoth1  \n     else   spotfile = $spotl1 \n     fi  \n\n     # threshold is set to -threshold 10 \n     LD_LIBRARY_PATH = $ldlp  ./search -data  $data  -ident  $i  -band  000  --nocheckpoint -output  $candout  -spotlight  $spotfile  -fpo  $fpo  -label  $name  -dt  2  -threshold  10  1   $name . $PBS_JOBID .out 2   $name . $PBS_JOBID .err\n\n   done  \n\n   #------------------------------------------  \n   # Search for coincidences among candidates  \n   #------------------------------------------ \n   echo   $name   $( date +%H:%M:%S )   coincidences     $PBS_O_WORKDIR /timing_ $FILENUM \n\n\n  mkdir -p  $coiout / $name ;   cd   $coiout / $name \n\n   # Copying the trigger files to the working directory  \n  cp  $candout /triggers* ${ name } *.bin .\n\n   # Name for the list of files  \n   st = $( ls triggers* ${ name } *.bin  |  tail -1 ) ;   listfile = ${ st : -16: 10 } _000 ${ st : -6: 2 } .list ; \n   echo   Name for the list of files:    $listfile  \n\n   echo   Removing the name of the pulsar from the triggers  files... \n   for  f in  $( ls triggers_*.bin ) ;   do  mv  $f   ${ f : 0 : 16 }${ f : -6: 6 } ;   done \n\n   echo   Vetoing: processing the triggers  files...  \n   for  f in  $( ls triggers_*.bin ) ;   do  \n     $coisrc /trigveto -noveto -fpo  $fpo   $f   \n     # Removing original triggers files  \n    rm  $f  \n   done  \n\n   echo   Removing candidates outside a narrow frequency band (+- 0.05)... \n   for  f in  $( ls pvc_*.bin ) ;   do \n     $coisrc /decym  $f   $fgw  0.05\n   done \n\n   echo   Writing list of pvc files to    $listfile  \n  ls pvc_*.bin    $listfile \n\n   echo   Searching for coincidences...  \n   for  i in  { 0..1 }{ 0..1 }{ 0..1 }{ 0..1 } ;   do  \n     $coisrc /coiproc -binary -refr  100  -scale_f  4  -scale_s  4  -scale_a  4  -scale_d  4  -shift  $i  -fpo  $fpo   $listfile  \n   done \n\n   echo   Generating the stat file...  \n   st = $( grep  Max value  *.resf  |  sort -gk  5   |  tail -1 ) \n   mcoi = $( echo   $st   |  awk  {print $5} ) \n   resf = $( echo   $st   |  awk  {print $1} ) \n   resf = ${ resf : 0 : 10 }  \n   $coisrc /resf2stat -threshold  $mcoi  -binary  $resf  \n\n   echo   Estimating the parameters... \n   $coisrc /stat2data -threshold  $mcoi  -refr  100  . *.stat\n\n   echo   Preparing the summary...  \n   st = $( find . -name  *.stat.dat  -printf  %f\\n ) \n   if   [  -z  $st   ] ;   then \n     echo   $name   $fpo   no coincidences    ../summary\n   else \n     echo   $name   $fpo   $( wc -l    $listfile )   $( awk  END{printf  %20s %.9e %.9e %.9e %.9e %.9e ,FILENAME,$3,$4,$5,$6,$7}   $st )    ../summary\n   fi  \n\n   # Cleanup (archiving and deleting the coi files)  \n   echo   $name   $( date +%H:%M:%S )   archiving coi files     $PBS_O_WORKDIR /timing_ $FILENUM \n\n   for  r in  $( ls *.coi ) ;   do  \n     ${ lz4path } /lz4 -6  ${ r }   ${ r } .lz4   gzip  ${ r } .lz4\n     if   [  -f  ${ r } .lz4.gz   ] ;   then  \n      rm  $r \n     fi  \n   done  \n\n   cd   $PBS_O_WORKDIR \n\n   echo   $name   $( date +%H:%M:%S )   end     $PBS_O_WORKDIR /timing_ $FILENUM  done    pulsar_file_ $FILENUM  exit  0  where the  pulsar_file_$FILENUM  contains 3 columns: pulsar  name ,  fpo  reference frequency and gravitational wave frequency of the pulsar  fgw . For an exemplary  pulsar_file_666 , contaning 8 pulsars,    J0440+6416 516.601562 516.721000\nJ0714-6355 538.630859 538.755400\nJ0424+3800 561.185547 561.302200\nJ0303-5616 1089.595703 1089.719400\nJ0612+3324 390.177734 390.297600\nJ0319-7629 466.138672 466.263800\nJ0803-6214 1700.154297 1700.281800\nJ0534+0935 258.660156 258.781000  the job can be sent to the PBS queue in the following way:    qsub -v FILENUM=666 -N mdc-666 pipeline.sh", 
            "title": "1. Sample PBS/Torque script"
        }, 
        {
            "location": "/pipeline_script/#2-sample-pbstorque-script-using-the-c-coincidences-code", 
            "text": "#!/bin/bash   #PBS -m n   #PBS -j oe  #PBS -q medium  #PBS -l mem=2GB  #PBS -l walltime=04:00:00  # Data directory   data = /work/psk/bejger/mdc/pulsar-data # Candidate (triggers) files output directory   candout = /work/psk/bejger/mdc/candidates-mdc-thr10 # Directory with coincidence codes   coisrc = /work/psk/bejger/mdc/ccoin # Coincidences output directory   coiout = /work/psk/bejger/mdc/coin-mdcthr10 # Path to the libraries (in the src/lib directory of the search code)  ldlp = /work/psk/bejger/mdc/spotlight/src/lib/yeppp-1.0.0/binaries/linux/x86_64 # Path to lz4 compressor  lz4path = /work/psk/bejger/codes/lz4-r131/programs cd   $PBS_O_WORKDIR  while   read  line ;   do \n\n   # pulsar name and frequency, and band frequency (from pulsar_file_$FILENUM) \n   # the master file is mdc_1561pulsars (name fpo f_gw)  \n   name = $( echo   $line   |  awk  {print $1} ) \n   fgw = $( echo   $line   |  awk  {print $3} ) \n   fpo = $( echo   $line   |  awk  {print $2} ) \n\n   #----------------------- \n   # Search for candidates  \n   #----------------------- \n   echo   $name   $( date +%H:%M:%S )   candidate search     $PBS_O_WORKDIR /timing_ $FILENUM \n\n   # search in frames xxx -- yyy   \n   for  i in  $( seq -f %03g  1  210 ) ;   do \n\n     # spotlight file range location  \n     spoth1 = ${ data } / ${ i } /H1/spot_ ${ name } .dat\n     spotl1 = ${ data } / ${ i } /L1/spot_ ${ name } .dat\n\n     # Here we assume that both H1 and L1 data is present for segment $i,  \n     # and take the H1 spotlight file to analyze it. If $spoth1 is not present,  \n     # it means there is no good H1 data. We then try $spotl1 as the spotlight file.   \n     # If both $spoth1 and $spotl1 are missing, it means there is no good data  \n     # and the code exits (since there is nothing to analyze). \n\n     spotfile = \n     if   [  -f  $spoth1   ] ;   then   spotfile = $spoth1  \n     else   spotfile = $spotl1 \n     fi  \n\n     # threshold is set to -threshold 10 \n     LD_LIBRARY_PATH = $ldlp  ./search -data  $data  -ident  $i  -band  000  --nocheckpoint -output  $candout  -spotlight  $spotfile  -fpo  $fpo  -label  $name  -dt  2  -threshold  10  1   $name . $PBS_JOBID .out 2   $name . $PBS_JOBID .err\n\n   done  \n\n   #------------------------------------------  \n   # Search for coincidences among candidates  \n   #------------------------------------------ \n   echo   $name   $( date +%H:%M:%S )   coinc: start     $PBS_O_WORKDIR /timing_ $FILENUM \n\n   # Creating a directory for each pulsar coincidence files  \n  mkdir -p  $coiout / $name \n\n   # Searching for coincidences  \n   for  shi in  { 0..1 }{ 0..1 }{ 0..1 }{ 0..1 } ;   do \n    ./coincidences -data  $candout  -trigname  $name  -refloc  ${ coisrc } /coinc-testdata -fpo  $fpo  -shift  $shi  -scale  4444  -refr  100  -dt  2  -mincoin  15  -narrowdown 0.2 -output  ${ coiout } / ${ name }  2   ${ coiout } / ${ name } /summary 1  /dev/null  \n   done \n\n   # Selecting maximal coincidence among all 16 shifts (col. 5)  \n   # If many, select the one with highest SNR (col. 10)   \n  sort -rgk5 -gk10  ${ coiout } / ${ name } /summary  |  head -1    ${ coiout } /summary \n\n   #------------------------------------------  \n   # Cleanup  \n   #------------------------------------------ \n\n   echo   $name   $( date +%H:%M:%S )   coinc: archiving coi files     $PBS_O_WORKDIR /timing_ $FILENUM \n\n   for  r in  $( ls  ${ coiout } / ${ name } /*.coi ) ;   do  \n     ${ lz4path } /lz4 -6  ${ r }   ${ r } .lz4   gzip  ${ r } .lz4\n     if   [  -f  ${ r } .lz4.gz   ] ;   then  \n      rm  $r \n     fi  \n   done  \n\n   echo   $name   $( date +%H:%M:%S )   coinc: end     $PBS_O_WORKDIR /timing_ $FILENUM  done    pulsar_file_ $FILENUM  exit  0", 
            "title": "2. Sample PBS/Torque script using the C coincidences code"
        }, 
        {
            "location": "/articles/", 
            "text": "List of documents and publications\n\n\nMethods\n\n\n\n\nData analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search\n \n(arXiv)\n\n\nData analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search\n \n(arXiv)\n\n\nBanks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars\n \n(arXiv)\n \n\n\n\n\nVirgo VSR1 data\n\n\n\n\nImplementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data\n \n(arXiv)\n\n\n\n\nMock Data Challenge using the LIGO S6 data\n\n\n\n\nA comparison of methods for the detection of gravitational waves from unknown neutron stars\n \n(arXiv)\n \n\n\n\n\nResonant bar detectors\n\n\n\n\nAll-sky search of NAUTILUS data\n \n(arXiv)\n\n\nAll-sky upper limit for gravitational radiation from spinning neutron stars\n \n(arXiv)\n\n\n\n\nMonographs\n\n\n\n\nGravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case\n\n\nAnalysis of Gravitational-Wave Data", 
            "title": "Documents and publications"
        }, 
        {
            "location": "/articles/#list-of-documents-and-publications", 
            "text": "", 
            "title": "List of documents and publications"
        }, 
        {
            "location": "/articles/#methods", 
            "text": "Data analysis of gravitational-wave signals from spinning neutron stars: The signal and its detection   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. II. Accuracy of estimation of parameters   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. III. Detection statistics and computational requirements   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. IV. An all-sky search   (arXiv)  Data analysis of gravitational-wave signals from spinning neutron stars. V. A narrow-band all-sky search   (arXiv)  Banks of templates for all-sky narrow-band searches of gravitational waves from spinning neutron stars   (arXiv)", 
            "title": "Methods"
        }, 
        {
            "location": "/articles/#virgo-vsr1-data", 
            "text": "Implementation of an F-statistic all-sky search for continuous gravitational waves in Virgo VSR1 data   (arXiv)", 
            "title": "Virgo VSR1 data"
        }, 
        {
            "location": "/articles/#mock-data-challenge-using-the-ligo-s6-data", 
            "text": "A comparison of methods for the detection of gravitational waves from unknown neutron stars   (arXiv)", 
            "title": "Mock Data Challenge using the LIGO S6 data"
        }, 
        {
            "location": "/articles/#resonant-bar-detectors", 
            "text": "All-sky search of NAUTILUS data   (arXiv)  All-sky upper limit for gravitational radiation from spinning neutron stars   (arXiv)", 
            "title": "Resonant bar detectors"
        }, 
        {
            "location": "/articles/#monographs", 
            "text": "Gravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case  Analysis of Gravitational-Wave Data", 
            "title": "Monographs"
        }
    ]
}